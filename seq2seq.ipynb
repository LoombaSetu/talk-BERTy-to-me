{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Change working directory to talk-berty-to-me root\n",
    "import os\n",
    "os.chdir(\"D:/University/Projects/AML/talk-berty-to-me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_CACHE_DIR = '/Users/setul/mlpp23/.vector_cache'\n",
    "glove = torchtext.vocab.GloVe('6B', cache=VECTOR_CACHE_DIR)\n",
    "glove_vectors = glove.get_vecs_by_tokens(vocab.get_itos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_gutenberg = pd.read_csv('data/books_and_genres.csv')\n",
    "# dataset_train = data_gutenberg.sample(frac=0.6, random_state=0)\n",
    "# dataset_val = data_gutenberg.drop(dataset_train.index).sample(frac=0.5, random_state=0)\n",
    "# dataset_test = data_gutenberg.drop(dataset_train.index).drop(\n",
    "#     dataset_val.index)\n",
    "# dataset_train.to_parquet('data/datasets/train.parquet', index=False)\n",
    "# dataset_test.to_parquet('data/datasets/test.parquet', index=False)\n",
    "# dataset_val.to_parquet('data/datasets/val.parquet', index=False)\n",
    "# data_gutenberg.sample(20).to_parquet('data/datasets/dev.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add code to switch between datasets here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = pd.read_parquet('data/datasets/dev.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building vocabulary\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab_iter = iter(dev_data.loc[:,'text'] + dev_data.loc[:,'title'] + dev_data.loc[:,'genres'])\n",
    "def yield_tokens(train_iter):\n",
    "    for text in train_iter:\n",
    "        if not isinstance(text, str):\n",
    "            if type(text) == list:\n",
    "                for t in text:\n",
    "                    yield tokenizer(t)\n",
    "            continue\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(vocab_iter), specials=[\"<unk>\"], min_freq=1000)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\setul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\setul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data.loc[:,'sentences'] = dev_data.loc[:,'text'].apply(lambda x: nltk.tokenize.sent_tokenize(str(x)))\n",
    "dev_data = dev_data.explode('sentences')\n",
    "#dev_data.loc[:,'keywords'] = dev_data.loc[:,'sentences'].apply(lambda x: rake_extract(x))\n",
    "dev_data = dev_data.loc[:,['title', 'sentences', 'genres']]\n",
    "dev_data.reset_index(drop=True, inplace=True)\n",
    "dev_data['label_sentences'] = dev_data.groupby('title')['sentences'].shift(-1)\n",
    "dev_data = dev_data.dropna(subset=['label_sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>sentences</th>\n",
       "      <th>genres</th>\n",
       "      <th>label_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14804</th>\n",
       "      <td>autobiography and selected essays</td>\n",
       "      <td>2.</td>\n",
       "      <td>{'biography', 'non-fiction'}</td>\n",
       "      <td>Which essay seems to you to be most successful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14805</th>\n",
       "      <td>autobiography and selected essays</td>\n",
       "      <td>Which essay seems to you to be most successful...</td>\n",
       "      <td>{'biography', 'non-fiction'}</td>\n",
       "      <td>3.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14806</th>\n",
       "      <td>autobiography and selected essays</td>\n",
       "      <td>3.</td>\n",
       "      <td>{'biography', 'non-fiction'}</td>\n",
       "      <td>Has the character of the audience any influenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14807</th>\n",
       "      <td>autobiography and selected essays</td>\n",
       "      <td>Has the character of the audience any influenc...</td>\n",
       "      <td>{'biography', 'non-fiction'}</td>\n",
       "      <td>4.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14808</th>\n",
       "      <td>autobiography and selected essays</td>\n",
       "      <td>4.</td>\n",
       "      <td>{'biography', 'non-fiction'}</td>\n",
       "      <td>Compare the structure of one of Huxley's essay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14809</th>\n",
       "      <td>autobiography and selected essays</td>\n",
       "      <td>Compare the structure of one of Huxley's essay...</td>\n",
       "      <td>{'biography', 'non-fiction'}</td>\n",
       "      <td>5.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title  \\\n",
       "14804  autobiography and selected essays   \n",
       "14805  autobiography and selected essays   \n",
       "14806  autobiography and selected essays   \n",
       "14807  autobiography and selected essays   \n",
       "14808  autobiography and selected essays   \n",
       "14809  autobiography and selected essays   \n",
       "\n",
       "                                               sentences  \\\n",
       "14804                                                 2.   \n",
       "14805  Which essay seems to you to be most successful...   \n",
       "14806                                                 3.   \n",
       "14807  Has the character of the audience any influenc...   \n",
       "14808                                                 4.   \n",
       "14809  Compare the structure of one of Huxley's essay...   \n",
       "\n",
       "                             genres  \\\n",
       "14804  {'biography', 'non-fiction'}   \n",
       "14805  {'biography', 'non-fiction'}   \n",
       "14806  {'biography', 'non-fiction'}   \n",
       "14807  {'biography', 'non-fiction'}   \n",
       "14808  {'biography', 'non-fiction'}   \n",
       "14809  {'biography', 'non-fiction'}   \n",
       "\n",
       "                                         label_sentences  \n",
       "14804  Which essay seems to you to be most successful...  \n",
       "14805                                                 3.  \n",
       "14806  Has the character of the audience any influenc...  \n",
       "14807                                                 4.  \n",
       "14808  Compare the structure of one of Huxley's essay...  \n",
       "14809                                                 5.  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data.iloc[14800:14806]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def collate_batch(batch):\n",
    "    titles, genres, sentences, label_sentences = zip(*batch)\n",
    "    context = [tokenizer(g) + ['<BOS>'] + tokenizer(t) + ['<EOS>'] +\n",
    "               ['<BOS>'] + tokenizer(s) + ['<EOS>'] for t, g,\n",
    "                s in zip(titles, genres, sentences)]\n",
    "    label_sentence = [['<BOS>'] + tokenizer(s) + ['<EOS>'] for s in label_sentences]\n",
    "    label_tensor = pad_sequence([torch.tensor(vocab.lookup_indices(t)) for t in label_sentence],\n",
    "                                    padding_value=vocab['<pad>'], batch_first=True)\n",
    "    encoder_tensor = pad_sequence([torch.tensor(vocab.lookup_indices(t)) for t in context],\n",
    "                                 padding_value=vocab['<pad>'], batch_first=True)\n",
    "    return encoder_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From HW4\n",
    "from torch.utils.data import Sampler\n",
    "class BatchSequentialSampler(Sampler):\n",
    "    r\"\"\"Samples batches, s.t. the ith elements of each batch are sequential.\n",
    "\n",
    "    Args:\n",
    "        data_source (Dataset): dataset to sample from\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_source, batch_size):\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __iter__(self):\n",
    "        num_batches = len(self.data_source)//self.batch_size\n",
    "        for i in range(num_batches):\n",
    "            for j in range(self.batch_size):\n",
    "                yield(j * num_batches + i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.data_source)//self.batch_size) * self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sampler = BatchSequentialSampler(dev_data.loc[:,['title', 'genres', 'sentences', 'label_sentences']], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dataloader = torch.utils.data.DataLoader(dev_data.loc[:,['title', 'genres', 'sentences', 'label_sentences']].values,\n",
    "                                                   batch_size=8, collate_fn=collate_batch, sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 90])\n",
      "torch.Size([8, 33])\n"
     ]
    }
   ],
   "source": [
    "for idx, (context_tensor, label_tensor) in enumerate(batch_dataloader):\n",
    "    print(context_tensor.shape)\n",
    "    print(label_tensor.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "IS_CUDA = torch.cuda.is_available()\n",
    "if IS_CUDA:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN_encoder(nn.Module):\n",
    "    def __init__ (self, embedding_dim, hidden_dim,\n",
    "                  vocab_size, num_layers=2, type_rnn = 'LSTM', bidirectional = True,\n",
    "                  dropout = 0.3, pad_idx = 0):\n",
    "        super(BiRNN_encoder, self).__init__()\n",
    "        self.rnns = []\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        hidden_size = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "        input_size = embedding_dim\n",
    "        for _ in range(num_layers):\n",
    "            if type_rnn == 'LSTM':\n",
    "                rnn = nn.LSTM(input_size, hidden_size, 1, dropout = dropout,\n",
    "                               bidirectional = bidirectional, batch_first=True)\n",
    "            elif type_rnn == 'GRU':\n",
    "                rnn = nn.GRU(input_size, hidden_size, 1, dropout = dropout,\n",
    "                              bidirectional = bidirectional, batch_first=True)\n",
    "            self.rnns.append(rnn)\n",
    "            input_size = hidden_size*2 if bidirectional else hidden_size\n",
    "        self.rnns = nn.ModuleList(self.rnns)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.type_rnn = type_rnn\n",
    "        self.bidirectional = bidirectional\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, input, hidden = None):\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.dropout(embedded)\n",
    "        rnn_input = embedded\n",
    "        for idx, rnn in enumerate(self.rnns):\n",
    "            output, hidden_output = rnn(rnn_input, hidden)\n",
    "            hidden = hidden_output\n",
    "            rnn_input = output\n",
    "        if self.type_rnn == 'LSTM' and self.bidirectional:\n",
    "            hidden_state = torch.cat((hidden[0][-2,:,:], hidden[0][-1,:,:]), dim = 1)\n",
    "            cell = torch.cat((hidden[1][-2,:,:], hidden[1][-1,:,:]), dim = 1)\n",
    "            hidden = (hidden_state, cell)\n",
    "        elif self.type_rnn == 'GRU' and self.bidirectional:\n",
    "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = BiRNN_encoder(300, 600, len(vocab), num_layers=2, type_rnn = 'LSTM',\n",
    "                         bidirectional = True, dropout = 0.3, pad_idx = vocab['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2400])\n",
      "torch.Size([8, 2400])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(batch_dataloader):\n",
    "    context_tensor, label_tensor = batch\n",
    "    hidden,cell = encoder(context_tensor)\n",
    "    print(hidden.shape)\n",
    "    print(cell.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN_decoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_layers, vocab_dim, dropout = 0.3):\n",
    "        super(BiRNN_decoder, self).__init__()\n",
    "        #self.input_size = input_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.vocab_dim = vocab_dim\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.embedding = nn.Embedding(vocab_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers, dropout = dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, vocab_dim)\n",
    "\n",
    "\n",
    "    def forward(self, input, hidden, context):\n",
    "        #input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # hidden = hidden.unsqueeze(0)\n",
    "        # context = context.unsqueeze(0)\n",
    "        print(\"input decoder LSTM emb\",embedded.shape)\n",
    "        print(\"input decoder LSTM hid\",hidden.shape)\n",
    "        print(\"input decoder LSTM ctx\",context.shape)\n",
    "        outputs, (hidden,context) = self.rnn(embedded, (hidden, context))\n",
    "        predictions = self.fc_out(outputs)\n",
    "        predictions = predictions.squeeze(0)\n",
    "        return predictions, hidden, context\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\setul\\miniconda3\\envs\\talk-berty\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "decoder = BiRNN_decoder(300, 2400, 1, len(vocab), dropout = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, src, trg, teacher_ratio = 0.5):\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        print(\"target length\", trg.shape)\n",
    "        trg_vocab_size = len(vocab)\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size)\n",
    "        hidden, context = self.encoder(src)\n",
    "        input = trg[:, 0]\n",
    "        input = input.unsqueeze(0)\n",
    "        hidden = hidden.unsqueeze(0)\n",
    "        context = context.unsqueeze(0)\n",
    "        for t in range(1, trg_len):\n",
    "            print(\"t\", t)\n",
    "            output, hidden, context = self.decoder(input, hidden, context)\n",
    "            outputs[t] = output\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[:,t] if np.random.random() < teacher_ratio else top1\n",
    "            input = input.unsqueeze(0)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 / 100\n",
      "target length torch.Size([8, 33])\n",
      "t 1\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 2\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 3\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 4\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 5\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 6\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 7\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 8\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 9\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 10\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 11\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 12\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 13\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 14\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 15\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 16\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 17\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 18\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 19\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 20\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 21\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 22\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 23\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 24\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 25\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 26\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 27\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 28\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 29\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 30\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 31\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "t 32\n",
      "input decoder LSTM emb torch.Size([1, 8, 300])\n",
      "input decoder LSTM hid torch.Size([1, 8, 2400])\n",
      "input decoder LSTM ctx torch.Size([1, 8, 2400])\n",
      "output torch.Size([8, 149])\n",
      "output_pre torch.Size([33, 8, 149])\n",
      "output_post torch.Size([256, 149])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (256) to match target batch_size (231).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[161], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Calculate the loss value for every epoch\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Calculate the gradients for weights & biases using back-propagation\u001b[39;00m\n\u001b[0;32m     29\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\setul\\miniconda3\\envs\\talk-berty\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\setul\\miniconda3\\envs\\talk-berty\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\setul\\miniconda3\\envs\\talk-berty\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\setul\\miniconda3\\envs\\talk-berty\\lib\\site-packages\\torch\\nn\\functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (256) to match target batch_size (231)."
     ]
    }
   ],
   "source": [
    "epoch_loss = 0.0\n",
    "num_epochs = 100\n",
    "best_loss = 999999\n",
    "best_epoch = -1\n",
    "sentence1 = \"Hello I am starting\"\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = vocab['<pad>'])\n",
    "ts1 = []\n",
    "for epoch in range(num_epochs):\n",
    "  print(\"Epoch - {} / {}\".format(epoch+1, num_epochs))\n",
    "  model.train(True)\n",
    "  for batch_idx, batch in enumerate(batch_dataloader):\n",
    "    input , target = batch\n",
    "\n",
    "    # Pass the input and target for model's forward method\n",
    "    output = model(input, target)\n",
    "    print(\"output_pre\", output.shape)\n",
    "    output = output[1:].reshape(-1, output.shape[2])\n",
    "    print(\"output_post\", output.shape)\n",
    "    target = target[1:].reshape(-1)\n",
    "\n",
    "    # Clear the accumulating gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Calculate the loss value for every epoch\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    # Calculate the gradients for weights & biases using back-propagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip the gradient value is it exceeds > 1\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "    # Update the weights values using the gradients we calculated using bp \n",
    "    optimizer.step()\n",
    "    #step += 1\n",
    "    epoch_loss += loss.item()\n",
    "    #writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "\n",
    "  if epoch_loss < best_loss:\n",
    "    best_loss = epoch_loss\n",
    "    best_epoch = epoch\n",
    "    if ((epoch - best_epoch) >= 10):\n",
    "      print(\"no improvement in 10 epochs, break\")\n",
    "      break\n",
    "  print(\"Epoch_Loss - {}\".format(loss.item()))\n",
    "  print()\n",
    "  \n",
    "print(epoch_loss / len(batch_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "the companions of jehu                13056\n",
       "the iron woman                        10553\n",
       "married                                5821\n",
       "his second wife                        5505\n",
       "fruits of culture                      4544\n",
       "life of jesus christ                   3960\n",
       "sir mortimer                           3867\n",
       "nouvelles histoires                    3599\n",
       "driven back to eden                    3414\n",
       "the confessions of artemas quibble     2429\n",
       "an attic philosopher complete          2256\n",
       "the story of silk                      2127\n",
       "a journal of the plague year           2012\n",
       "autobiography and selected essays      1888\n",
       "oedipus king of thebes                 1780\n",
       "the suffrage cook book                 1745\n",
       "building a state in apache land         733\n",
       "z marcas                                486\n",
       "the undersea tube                       224\n",
       "el consejo de los dioses                207\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data.loc[:,'title'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "talk-berty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
