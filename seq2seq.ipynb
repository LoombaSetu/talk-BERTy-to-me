{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Change working directory to talk-berty-to-me root\n",
    "import os\n",
    "os.chdir(\"D:/University/Projects/AML/talk-berty-to-me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_gutenberg = pd.read_csv('data/books_and_genres.csv')\n",
    "# dataset_train = data_gutenberg.sample(frac=0.6, random_state=0)\n",
    "# dataset_val = data_gutenberg.drop(dataset_train.index).sample(frac=0.5, random_state=0)\n",
    "# dataset_test = data_gutenberg.drop(dataset_train.index).drop(\n",
    "#     dataset_val.index)\n",
    "# dataset_train.to_parquet('data/datasets/train.parquet', index=False)\n",
    "# dataset_test.to_parquet('data/datasets/test.parquet', index=False)\n",
    "# dataset_val.to_parquet('data/datasets/val.parquet', index=False)\n",
    "# data_gutenberg.sample(20).to_parquet('data/datasets/dev.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add code to switch between datasets here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_data = pd.read_parquet('data/datasets/dev.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('data/books_and_genres_eng.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = raw_data.sample(20)\n",
    "dev_data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "###Creating a validation set\n",
    "val_data = raw_data.sample(5)\n",
    "val_data.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>genres</th>\n",
       "      <th>language_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>the three musketeers</td>\n",
       "      <td>Produced by John P. Roberts III, Roger Labbe, ...</td>\n",
       "      <td>{'history', 'classics', 'novels', 'fiction', '...</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>the frogs</td>\n",
       "      <td>Produced by Ted Garvin, Marvin A. Hodges, Char...</td>\n",
       "      <td>{'classics', 'mythology', 'literature', 'ficti...</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>paradise lost</td>\n",
       "      <td>This is the February 1992 Project Gutenberg re...</td>\n",
       "      <td>{'literary-fiction', 'mythology', 'historical-...</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>black beauty</td>\n",
       "      <td>Produced by A. Light, Linda Bowser, and David ...</td>\n",
       "      <td>{'adventure', 'middle-grade', 'classics', 'ani...</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>creatures of the night</td>\n",
       "      <td>Produced by David Edwards, Marcia Brooks and t...</td>\n",
       "      <td>{'horror', 'animals', 'comics', 'fantasy', 'pa...</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  \\\n",
       "44     the three musketeers   \n",
       "390               the frogs   \n",
       "245           paradise lost   \n",
       "272            black beauty   \n",
       "303  creatures of the night   \n",
       "\n",
       "                                                  text  \\\n",
       "44   Produced by John P. Roberts III, Roger Labbe, ...   \n",
       "390  Produced by Ted Garvin, Marvin A. Hodges, Char...   \n",
       "245  This is the February 1992 Project Gutenberg re...   \n",
       "272  Produced by A. Light, Linda Bowser, and David ...   \n",
       "303  Produced by David Edwards, Marcia Brooks and t...   \n",
       "\n",
       "                                                genres language_code  \n",
       "44   {'history', 'classics', 'novels', 'fiction', '...           eng  \n",
       "390  {'classics', 'mythology', 'literature', 'ficti...         en-US  \n",
       "245  {'literary-fiction', 'mythology', 'historical-...           eng  \n",
       "272  {'adventure', 'middle-grade', 'classics', 'ani...         en-US  \n",
       "303  {'horror', 'animals', 'comics', 'fantasy', 'pa...           eng  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>genres</th>\n",
       "      <th>language_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>success</td>\n",
       "      <td>Produced by Robert Shimmin, Mary Meehan, and t...</td>\n",
       "      <td>{'education', 'history', 'sociology', 'self-he...</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>sense and sensibility</td>\n",
       "      <td>Produced by Fritz Ohrenschall and Sankar Viswa...</td>\n",
       "      <td>{'romance', 'literary-fiction', 'classics', 'h...</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>the iliad</td>\n",
       "      <td>Produced by Anne Soulard, Charles Franks\\nand ...</td>\n",
       "      <td>{'adventure', 'history', 'mythology', 'histori...</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>inferno</td>\n",
       "      <td>Produced by Jens Sadowski, and Projekt Runeber...</td>\n",
       "      <td>{'literary-fiction', 'history', 'mythology', '...</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>selected poems</td>\n",
       "      <td>Produced by Juliet Sutherland, Tamiko I. Camac...</td>\n",
       "      <td>{'romance', 'classics', 'modern', 'literature'...</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                                               text  \\\n",
       "114                success  Produced by Robert Shimmin, Mary Meehan, and t...   \n",
       "130  sense and sensibility  Produced by Fritz Ohrenschall and Sankar Viswa...   \n",
       "428              the iliad  Produced by Anne Soulard, Charles Franks\\nand ...   \n",
       "311                inferno  Produced by Jens Sadowski, and Projekt Runeber...   \n",
       "60          selected poems  Produced by Juliet Sutherland, Tamiko I. Camac...   \n",
       "\n",
       "                                                genres language_code  \n",
       "114  {'education', 'history', 'sociology', 'self-he...           eng  \n",
       "130  {'romance', 'literary-fiction', 'classics', 'h...           eng  \n",
       "428  {'adventure', 'history', 'mythology', 'histori...           eng  \n",
       "311  {'literary-fiction', 'history', 'mythology', '...           eng  \n",
       "60   {'romance', 'classics', 'modern', 'literature'...           eng  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    Function to clean text of books. Removes email addresses, new lines, html tags, and extra spaces.\n",
    "\n",
    "    Input: Text (String)\n",
    "    Output: Cleaned Text (String)\n",
    "    '''\n",
    "    cleaned_text = text.lower()\n",
    "    cleaned_text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', ' ', text)\n",
    "    cleaned_text = re.sub(r'^.*?(?=\\n\\n\\n)', ' ', cleaned_text, flags=re.DOTALL)\n",
    "    cleaned_text = re.sub(r'<a\\s+(?:[^>]*?\\s+)?href=\"([^\"]*)\"[^>]*>.*?</a>', ' ', cleaned_text, flags=re.DOTALL)\n",
    "    cleaned_text = re.sub(r'\\n', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\d+', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'[^\\w\\s.?!]', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r' +', ' ', cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_first_row(group):\n",
    "    return group.iloc[1:]\n",
    "\n",
    "def lowercase(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data['cleaned_text'] = dev_data['text'].apply(lambda x:clean_text(x))\n",
    "dev_data.loc[:,'genres'] = dev_data.loc[:,'genres'].apply(lambda x:clean_text(x))\n",
    "dev_data.loc[:,'sentences'] = dev_data.loc[:,'cleaned_text'].apply(lambda x: nltk.tokenize.sent_tokenize(str(x)))\n",
    "dev_data = dev_data.explode('sentences')\n",
    "dev_data.loc[:,'sentences'] = dev_data.loc[:,'sentences'].apply(lambda x:lowercase(x))\n",
    "dev_data.reset_index(drop=True, inplace=True)\n",
    "dev_data['label_sentences'] = dev_data.groupby('title')['sentences'].shift(-1)\n",
    "dev_data = dev_data.dropna(subset=['label_sentences'])\n",
    "dev_data = dev_data.loc[:,['title', 'genres','sentences', 'label_sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data['cleaned_text'] = val_data['text'].apply(lambda x:clean_text(x))\n",
    "val_data.loc[:,'genres'] = val_data.loc[:,'genres'].apply(lambda x:clean_text(x))\n",
    "val_data.loc[:,'sentences'] = val_data.loc[:,'cleaned_text'].apply(lambda x: nltk.tokenize.sent_tokenize(str(x)))\n",
    "val_data = val_data.explode('sentences')\n",
    "val_data.loc[:,'sentences'] = val_data.loc[:,'sentences'].apply(lambda x:lowercase(x))\n",
    "val_data.reset_index(drop=True, inplace=True)\n",
    "val_data['label_sentences'] = val_data.groupby('title')['sentences'].shift(-1)\n",
    "val_data = val_data.dropna(subset=['label_sentences'])\n",
    "val_data = val_data.loc[:,['title', 'genres','sentences', 'label_sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>sentences</th>\n",
       "      <th>label_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the three musketeers</td>\n",
       "      <td>history classics novels fiction historical fi...</td>\n",
       "      <td>the three musketeers alexandre dumas contents...</td>\n",
       "      <td>the three presents of d artagnan the elder .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the three musketeers</td>\n",
       "      <td>history classics novels fiction historical fi...</td>\n",
       "      <td>the three presents of d artagnan the elder .</td>\n",
       "      <td>the antechamber of m. de treville .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the three musketeers</td>\n",
       "      <td>history classics novels fiction historical fi...</td>\n",
       "      <td>the antechamber of m. de treville .</td>\n",
       "      <td>the audience .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the three musketeers</td>\n",
       "      <td>history classics novels fiction historical fi...</td>\n",
       "      <td>the audience .</td>\n",
       "      <td>the shoulder of athos the baldric of porthos a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the three musketeers</td>\n",
       "      <td>history classics novels fiction historical fi...</td>\n",
       "      <td>the shoulder of athos the baldric of porthos a...</td>\n",
       "      <td>the king s musketeers and the cardinal s guards .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                             genres  \\\n",
       "0  the three musketeers   history classics novels fiction historical fi...   \n",
       "1  the three musketeers   history classics novels fiction historical fi...   \n",
       "2  the three musketeers   history classics novels fiction historical fi...   \n",
       "3  the three musketeers   history classics novels fiction historical fi...   \n",
       "4  the three musketeers   history classics novels fiction historical fi...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0   the three musketeers alexandre dumas contents...   \n",
       "1       the three presents of d artagnan the elder .   \n",
       "2                the antechamber of m. de treville .   \n",
       "3                                     the audience .   \n",
       "4  the shoulder of athos the baldric of porthos a...   \n",
       "\n",
       "                                     label_sentences  \n",
       "0       the three presents of d artagnan the elder .  \n",
       "1                the antechamber of m. de treville .  \n",
       "2                                     the audience .  \n",
       "3  the shoulder of athos the baldric of porthos a...  \n",
       "4  the king s musketeers and the cardinal s guards .  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data = dev_data.loc[:,['title', 'genres','sentences', 'label_sentences']]\n",
    "dev_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>sentences</th>\n",
       "      <th>label_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>education history sociology self help psychol...</td>\n",
       "      <td>success by samuel hopkins adams author of the...</td>\n",
       "      <td>contents part i. enchantment part ii.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>success</td>\n",
       "      <td>education history sociology self help psychol...</td>\n",
       "      <td>contents part i. enchantment part ii.</td>\n",
       "      <td>the vision part iii.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>success</td>\n",
       "      <td>education history sociology self help psychol...</td>\n",
       "      <td>the vision part iii.</td>\n",
       "      <td>fulfillment success part i enchantment chapter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>success</td>\n",
       "      <td>education history sociology self help psychol...</td>\n",
       "      <td>fulfillment success part i enchantment chapter...</td>\n",
       "      <td>a mile away in a dip of the desert lay the tow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>success</td>\n",
       "      <td>education history sociology self help psychol...</td>\n",
       "      <td>a mile away in a dip of the desert lay the tow...</td>\n",
       "      <td>far as the eye could see the waste was spangle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     title                                             genres  \\\n",
       "0  success   education history sociology self help psychol...   \n",
       "1  success   education history sociology self help psychol...   \n",
       "2  success   education history sociology self help psychol...   \n",
       "3  success   education history sociology self help psychol...   \n",
       "4  success   education history sociology self help psychol...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0   success by samuel hopkins adams author of the...   \n",
       "1              contents part i. enchantment part ii.   \n",
       "2                               the vision part iii.   \n",
       "3  fulfillment success part i enchantment chapter...   \n",
       "4  a mile away in a dip of the desert lay the tow...   \n",
       "\n",
       "                                     label_sentences  \n",
       "0              contents part i. enchantment part ii.  \n",
       "1                               the vision part iii.  \n",
       "2  fulfillment success part i enchantment chapter...  \n",
       "3  a mile away in a dip of the desert lay the tow...  \n",
       "4  far as the eye could see the waste was spangle...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data = val_data.loc[:,['title', 'genres','sentences', 'label_sentences']]\n",
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'listen to aramis said his three friends.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data.loc[1900, 'sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building vocabulary\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab_iter = iter(dev_data.loc[:,'sentences'] + dev_data.loc[:,'title'] + dev_data.loc[:,'genres'])\n",
    "def yield_tokens(train_iter):\n",
    "    for text in train_iter:\n",
    "        if not isinstance(text, str):\n",
    "            if type(text) == list:\n",
    "                for t in text:\n",
    "                    yield tokenizer(t)\n",
    "            continue\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(vocab_iter), specials=[\"<unk>\", \"<pad>\", \"<BOS>\", \"<EOS>\"], min_freq=50)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3522"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_CACHE_DIR = '/Users/setul/mlpp23/.vector_cache'\n",
    "glove = torchtext.vocab.GloVe('6B', cache=VECTOR_CACHE_DIR)\n",
    "glove_vectors = glove.get_vecs_by_tokens(vocab.get_itos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>sentences</th>\n",
       "      <th>label_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>the three musketeers</td>\n",
       "      <td>history classics novels fiction historical fi...</td>\n",
       "      <td>this is the second or third time monsieur that...</td>\n",
       "      <td>you do not know the man at whose shutter you h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>the three musketeers</td>\n",
       "      <td>history classics novels fiction historical fi...</td>\n",
       "      <td>you do not know the man at whose shutter you h...</td>\n",
       "      <td>indeed madame you believe me too credulous!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>the three musketeers</td>\n",
       "      <td>history classics novels fiction historical fi...</td>\n",
       "      <td>indeed madame you believe me too credulous!</td>\n",
       "      <td>confess that it is for the sake of making me t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>the three musketeers</td>\n",
       "      <td>history classics novels fiction historical fi...</td>\n",
       "      <td>confess that it is for the sake of making me t...</td>\n",
       "      <td>i invent nothing madame i create nothing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>the three musketeers</td>\n",
       "      <td>history classics novels fiction historical fi...</td>\n",
       "      <td>i invent nothing madame i create nothing.</td>\n",
       "      <td>i only speak that exact truth.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>the three musketeers</td>\n",
       "      <td>history classics novels fiction historical fi...</td>\n",
       "      <td>i only speak that exact truth.</td>\n",
       "      <td>and you say that one of your friends lives in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                                             genres  \\\n",
       "2480  the three musketeers   history classics novels fiction historical fi...   \n",
       "2481  the three musketeers   history classics novels fiction historical fi...   \n",
       "2482  the three musketeers   history classics novels fiction historical fi...   \n",
       "2483  the three musketeers   history classics novels fiction historical fi...   \n",
       "2484  the three musketeers   history classics novels fiction historical fi...   \n",
       "2485  the three musketeers   history classics novels fiction historical fi...   \n",
       "\n",
       "                                              sentences  \\\n",
       "2480  this is the second or third time monsieur that...   \n",
       "2481  you do not know the man at whose shutter you h...   \n",
       "2482        indeed madame you believe me too credulous!   \n",
       "2483  confess that it is for the sake of making me t...   \n",
       "2484          i invent nothing madame i create nothing.   \n",
       "2485                     i only speak that exact truth.   \n",
       "\n",
       "                                        label_sentences  \n",
       "2480  you do not know the man at whose shutter you h...  \n",
       "2481        indeed madame you believe me too credulous!  \n",
       "2482  confess that it is for the sake of making me t...  \n",
       "2483          i invent nothing madame i create nothing.  \n",
       "2484                     i only speak that exact truth.  \n",
       "2485  and you say that one of your friends lives in ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data.iloc[2480:2486]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "IS_CUDA = torch.cuda.is_available()\n",
    "if IS_CUDA:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def collate_batch(batch):\n",
    "    titles, genres, sentences, label_sentences = zip(*batch)\n",
    "    #Add a separator tag between title and genre\n",
    "    context = [tokenizer(g) + ['<pad>'] + tokenizer(t) + ['<pad>'] +\n",
    "               ['<BOS>'] + tokenizer(s) + ['<EOS>'] for t, g,\n",
    "                s in zip(titles, genres, sentences)]\n",
    "    label_sentence = [['<BOS>'] + tokenizer(s) + ['<EOS>'] for s in label_sentences]\n",
    "    label_tensor = pad_sequence([torch.tensor(vocab.lookup_indices(t)) for t in label_sentence],\n",
    "                                    padding_value=vocab['<pad>'], batch_first=True)\n",
    "    encoder_tensor = pad_sequence([torch.tensor(vocab.lookup_indices(t)) for t in context],\n",
    "                                 padding_value=vocab['<pad>'], batch_first=True)\n",
    "    return encoder_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From HW4\n",
    "from torch.utils.data import Sampler\n",
    "class BatchSequentialSampler(Sampler):\n",
    "    r\"\"\"Samples batches, s.t. the ith elements of each batch are sequential.\n",
    "\n",
    "    Args:\n",
    "        data_source (Dataset): dataset to sample from\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_source, batch_size):\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __iter__(self):\n",
    "        num_batches = len(self.data_source)//self.batch_size\n",
    "        for i in range(num_batches):\n",
    "            for j in range(self.batch_size):\n",
    "                yield(j * num_batches + i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.data_source)//self.batch_size) * self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sampler = BatchSequentialSampler(dev_data.loc[:,['title', 'genres', 'sentences', 'label_sentences']], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dataloader = torch.utils.data.DataLoader(dev_data.loc[:,['title', 'genres', 'sentences', 'label_sentences']].values,\n",
    "                                                   batch_size=8, collate_fn=collate_batch, sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sampler = BatchSequentialSampler(val_data.loc[:,['title', 'genres', 'sentences', 'label_sentences']], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = torch.utils.data.DataLoader(val_data.loc[:,['title', 'genres', 'sentences', 'label_sentences']].values,\n",
    "                                                   batch_size=8, collate_fn=collate_batch, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 46])\n",
      "torch.Size([8, 21])\n"
     ]
    }
   ],
   "source": [
    "for idx, (context_tensor, label_tensor) in enumerate(batch_dataloader):\n",
    "    print(context_tensor.shape)\n",
    "    print(label_tensor.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN_encoder(nn.Module):\n",
    "    def __init__ (self, embedding_dim, hidden_dim,\n",
    "                  vocab_size, num_layers=2, type_rnn = 'LSTM', bidirectional = True,\n",
    "                  dropout = 0.3, pad_idx = 0):\n",
    "        super(BiRNN_encoder, self).__init__()\n",
    "        self.rnns = []\n",
    "        # self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx).to(device)\n",
    "        self.embedding = nn.Embedding.from_pretrained(glove_vectors).to(device)\n",
    "        hidden_size = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "        input_size = embedding_dim\n",
    "        for _ in range(num_layers):\n",
    "            if type_rnn == 'LSTM':\n",
    "                rnn = nn.LSTM(input_size, hidden_size, 1, dropout = dropout,\n",
    "                               bidirectional = bidirectional, batch_first=True).to(device)\n",
    "            elif type_rnn == 'GRU':\n",
    "                rnn = nn.GRU(input_size, hidden_size, 1, dropout = dropout,\n",
    "                              bidirectional = bidirectional, batch_first=True).to(device)\n",
    "            self.rnns.append(rnn)\n",
    "            input_size = hidden_size*2 if bidirectional else hidden_size\n",
    "        self.rnns = nn.ModuleList(self.rnns).to(device)\n",
    "        self.dropout = nn.Dropout(dropout).to(device)\n",
    "        self.type_rnn = type_rnn\n",
    "        self.bidirectional = bidirectional\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, input, hidden = None):\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.dropout(embedded)\n",
    "        rnn_input = embedded\n",
    "        for idx, rnn in enumerate(self.rnns):\n",
    "            output, hidden_output = rnn(rnn_input, hidden)\n",
    "            hidden = hidden_output\n",
    "            rnn_input = output\n",
    "        if self.type_rnn == 'LSTM' and self.bidirectional:\n",
    "            hidden_state = torch.cat((hidden[0][-2,:,:], hidden[0][-1,:,:]), dim = 1).to(device)\n",
    "            cell = torch.cat((hidden[1][-2,:,:], hidden[1][-1,:,:]), dim = 1).to(device)\n",
    "            hidden = (hidden_state, cell)\n",
    "        elif self.type_rnn == 'GRU' and self.bidirectional:\n",
    "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1).to(device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\setul\\miniconda3\\envs\\talk-berty\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "encoder = BiRNN_encoder(300, 600, len(vocab), num_layers=2, type_rnn = 'LSTM',\n",
    "                         bidirectional = True, dropout = 0.3, pad_idx = vocab['<pad>']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2400])\n",
      "torch.Size([8, 2400])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(batch_dataloader):\n",
    "    context_tensor, label_tensor = batch\n",
    "    context_tensor, label_tensor = context_tensor.to(device), label_tensor.to(device)\n",
    "    hidden,cell = encoder(context_tensor)\n",
    "    print(hidden.shape)\n",
    "    print(cell.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN_decoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_layers, vocab_dim, dropout = 0.3):\n",
    "        super(BiRNN_decoder, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.vocab_dim = vocab_dim\n",
    "        self.dropout = nn.Dropout(dropout).to(device)\n",
    "        # self.embedding = nn.Embedding(vocab_dim, embedding_dim).to(device)\n",
    "        self.embedding = nn.Embedding.from_pretrained(glove_vectors).to(device)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers, dropout = dropout).to(device)\n",
    "        self.fc_out = nn.Linear(hidden_dim, vocab_dim).to(device)\n",
    "\n",
    "\n",
    "    def forward(self, input, hidden, context):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        outputs, (hidden,context) = self.rnn(embedded, (hidden, context))\n",
    "        predictions = self.fc_out(outputs)\n",
    "        predictions = predictions.squeeze(0)\n",
    "        return predictions, hidden, context\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = BiRNN_decoder(300, 2400, 1, len(vocab), dropout = 0.3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, src, trg, teacher_ratio = 0.5):\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = len(vocab)\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(device)\n",
    "        hidden, context = self.encoder(src)\n",
    "        hidden = hidden.detach()\n",
    "        context = context.detach()\n",
    "        dec_input = trg[:, 0]\n",
    "        dec_input = dec_input.unsqueeze(0)\n",
    "        hidden = hidden.unsqueeze(0)\n",
    "        context = context.unsqueeze(0)\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, context = self.decoder(dec_input, hidden, context)\n",
    "            outputs[t] = output\n",
    "            top1 = output.argmax(1)\n",
    "            dec_input = trg[:,t] if np.random.random() < teacher_ratio else top1\n",
    "            dec_input = dec_input.unsqueeze(0)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader):\n",
    "    '''\n",
    "    Evaluate the model on the given data.\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "    it = iter(data_loader)\n",
    "    total_count = 0. # Number of target words seen\n",
    "    total_loss = 0. # Loss over all target words\n",
    "    with torch.no_grad():\n",
    "        # No gradients need to be maintained during evaluation\n",
    "        # There are no hidden tensors for the first batch, and so will default to zeros.\n",
    "        hidden = None \n",
    "        for i, batch in enumerate(it):\n",
    "            text, target = batch\n",
    "            if USE_CUDA:\n",
    "                text, target = text.cuda(), target.cuda()\n",
    "            output = model(text, target).to(device)\n",
    "            mask = (target != PAD_IDX)\n",
    "            ntotal = mask.sum()\n",
    "            loss = loss_fn(output.view(-1, output.size(-1)), target.view(-1))\n",
    "            \n",
    "            total_count += ntotal\n",
    "            total_loss += loss.item()*ntotal\n",
    "                \n",
    "    loss = total_loss / total_count\n",
    "    model.train()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ChatGPT's improvement\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_count = 0  # Total number of non-<pad> tokens\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for text, target in data_loader:\n",
    "            if USE_CUDA:\n",
    "                text, target = text.cuda(), target.cuda()\n",
    "\n",
    "            output = model(text, target)\n",
    "            mask = (target != PAD_IDX)  # Create a mask for non-pad tokens\n",
    "            ntotal = mask.sum().item()  # Sum the mask values to get the total number of non-<pad> tokens\n",
    "\n",
    "            # Apply mask to filter out loss contributions from <pad> tokens and compute the loss\n",
    "            loss = loss_fn(output.view(-1, output.size(-1)), target.view(-1))\n",
    "            loss = loss.masked_select(mask.view(-1)).mean()  # Only consider non-<pad> tokens and compute mean loss\n",
    "            \n",
    "            total_loss += loss.item() * ntotal  # Accumulate the total loss\n",
    "            total_count += ntotal  # Accumulate the total count of non-<pad> tokens\n",
    "\n",
    "    average_loss = total_loss / total_count  # Compute the average loss over all non-<pad> tokens\n",
    "    model.train()\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iter 0 loss 8.165975570678711\n"
     ]
    }
   ],
   "source": [
    "LOG_FILE = \"language-model.log\"\n",
    "GRAD_CLIP = 1.\n",
    "NUM_EPOCHS = 10\n",
    "PAD_IDX = vocab['<pad>']\n",
    "\n",
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "    if h is None:\n",
    "        return None\n",
    "    elif isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)\n",
    "    \n",
    "    \n",
    "seq_model = Seq2Seq(encoder, decoder).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index = PAD_IDX, reduction = 'sum') ## Used instead of NLLLoss.\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(seq_model.parameters(), lr=learning_rate)\n",
    "val_losses = []\n",
    "best_model = None\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    seq_model.train()\n",
    "    it = iter(batch_dataloader)\n",
    "    for i, batch in enumerate(it):\n",
    "        data, target = batch\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = seq_model(data, target).to(device)\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[:,1:].reshape(-1)\n",
    "        optimizer.zero_grad()\n",
    "        mask = (target != PAD_IDX)\n",
    "        ntotal = mask.sum()\n",
    "        loss = loss_fn(output, target)\n",
    "        loss = loss / ntotal\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(seq_model.parameters(), GRAD_CLIP)\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(\"epoch\", epoch, \"iter\", i, \"loss\", loss.item())\n",
    "\n",
    "        if i % 10000 == 0:\n",
    "            val_loss = evaluate(seq_model, val_dataloader)\n",
    "            with open(LOG_FILE, \"a\") as fout:\n",
    "                #print(\"epoch: {}, iteration: {}, perplexity: {}\".format(epoch, i, np.exp(val_loss)))\n",
    "                fout.write(\"epoch: {}, iteration: {}, perplexity: {}\\n\".format(epoch, i, val_loss))\n",
    "\n",
    "            # Save the model if the validation loss is the minimum so far\n",
    "            if len(val_losses) == 0 or val_loss < min(val_losses):\n",
    "                print(\"best model, val loss: \", val_loss)\n",
    "                # #best_model = copy.deepcopy(model)\n",
    "                # best_model = type(seq_model)(vocab_size, EMBEDDING_SIZE, EMBEDDING_SIZE, 2, dropout=0.5)\n",
    "                # if USE_CUDA:\n",
    "                #     best_model = best_model.cuda()\n",
    "                # best_model.load_state_dict(model.state_dict())\n",
    "\n",
    "                # with open(PATH + \"lm-best.th\", \"wb\") as fout:\n",
    "                #     torch.save(best_model.state_dict(), fout)\n",
    "            else:\n",
    "                learning_rate /= 4.\n",
    "                optimizer = torch.optim.Adam(seq_model.parameters(), lr=learning_rate)\n",
    "            val_losses.append(val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##From other sources\n",
    "# epoch_loss = 0.0\n",
    "# num_epochs = 10\n",
    "# best_loss = 999999\n",
    "# best_epoch = -1\n",
    "# sentence1 = \"Hello I am starting\"\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# criterion = nn.CrossEntropyLoss(ignore_index = vocab['<pad>'])\n",
    "# ts1 = []\n",
    "# for epoch in range(num_epochs):\n",
    "#   print(\"Epoch - {} / {}\".format(epoch+1, num_epochs))\n",
    "#   model.train(True)\n",
    "#   for batch_idx, batch in enumerate(batch_dataloader):\n",
    "#     input , target = batch\n",
    "#     input, target = input.to(device), target.to(device)\n",
    "#     output = model(input, target).to(device)\n",
    "#     output = output[1:].reshape(-1, output.shape[2])\n",
    "#     target = target[:,1:].reshape(-1)\n",
    "    \n",
    "#     optimizer.zero_grad()\n",
    "#     loss = criterion(output, target)\n",
    "#     loss.backward()\n",
    "\n",
    "#     # Clip gradient >1 to prevent exploding gradients\n",
    "#     torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "#     # Update the weights values using the gradients we calculated using bp \n",
    "#     optimizer.step()\n",
    "#     #step += 1\n",
    "#     epoch_loss += loss.item()\n",
    "#     #writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "\n",
    "#   if epoch_loss < best_loss:\n",
    "#     best_loss = epoch_loss\n",
    "#     best_epoch = epoch\n",
    "#     if ((epoch - best_epoch) >= 3):\n",
    "#       print(\"no improvement in 3 epochs, break\")\n",
    "#       break\n",
    "#   print(\"Epoch_Loss - {}\".format(loss.item()))\n",
    "#   print()\n",
    "  \n",
    "# print(epoch_loss / len(batch_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(seq_model.state_dict(), 'seq_model_functional.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, input_genre, input_title, input_text, max_length=10):\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize and prepare input text\n",
    "    input_tokens = (tokenizer(input_genre) + ['<pad>'] + tokenizer(input_title) + ['<pad>'] +\n",
    "    ['<BOS>'] + tokenizer(input_text) + ['<EOS>'])\n",
    "    input_indices = vocab.lookup_indices(input_tokens)\n",
    "    input_tensor = torch.tensor([input_indices], dtype=torch.long, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden, context = model.encoder(input_tensor)\n",
    "    decoder_input = torch.tensor([[vocab['<BOS>']]], device=device)  \n",
    "    output_indices = []\n",
    "    context = context.unsqueeze(0)\n",
    "    hidden = hidden.unsqueeze(0)\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        with torch.no_grad():\n",
    "            # print(\"decoder_shape\", decoder_input.shape)\n",
    "            # print(\"hidden_shape\", hidden.shape)\n",
    "            # print(\"context_shape\", context.shape)\n",
    "            output, hidden, context = model.decoder(decoder_input, hidden, context)\n",
    "            output_probabilities = output.squeeze().exp().to(device)\n",
    "            top1 = torch.multinomial(output_probabilities, 1)[0]\n",
    "            #top1 = torch.argmax(output)\n",
    "            # print(top1)\n",
    "            # print(\"top1 shape\", top1.shape)\n",
    "            # print(vocab.lookup_token(top1.item()))\n",
    "            #print(vocab.lookup_indices(list(top1)))\n",
    "            # print(top1)\n",
    "            if top1.item() == vocab['<EOS>']:\n",
    "                break\n",
    "            output_indices.append(top1.item())\n",
    "\n",
    "            decoder_input = torch.tensor([[top1.item()]], device=device)  \n",
    "    output_tokens = [vocab.lookup_token(index) for index in output_indices]\n",
    "    return ' '.join(output_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.lookup_token(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_title = \"autobiography\"\n",
    "input_genre = \"crime\"\n",
    "input_sentence = \"The room was close.\"\n",
    "generated_text = generate_text(seq_model, input_genre, input_title, input_sentence, max_length=50)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in seq_model.parameters():\n",
    "    print(\"param\", param.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "talk-berty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
