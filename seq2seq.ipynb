{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Change working directory to talk-berty-to-me root\n",
    "import os\n",
    "os.chdir(\"D:/University/Projects/AML/talk-berty-to-me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_gutenberg = pd.read_csv('data/books_and_genres.csv')\n",
    "# dataset_train = data_gutenberg.sample(frac=0.6, random_state=0)\n",
    "# dataset_val = data_gutenberg.drop(dataset_train.index).sample(frac=0.5, random_state=0)\n",
    "# dataset_test = data_gutenberg.drop(dataset_train.index).drop(\n",
    "#     dataset_val.index)\n",
    "# dataset_train.to_parquet('data/datasets/train.parquet', index=False)\n",
    "# dataset_test.to_parquet('data/datasets/test.parquet', index=False)\n",
    "# dataset_val.to_parquet('data/datasets/val.parquet', index=False)\n",
    "# data_gutenberg.sample(20).to_parquet('data/datasets/dev.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add code to switch between datasets here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_data = pd.read_parquet('data/datasets/dev.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('data/books_and_genres_eng.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>genres</th>\n",
       "      <th>language_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>the power and the glory</td>\n",
       "      <td>Produced by Juliet Sutherland, Sjaani and PG D...</td>\n",
       "      <td>{'literary-fiction', 'christian', 'history', '...</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>paradise</td>\n",
       "      <td>Produced by Judith Smith and Natalie Salter\\n\\...</td>\n",
       "      <td>{'literary-fiction', 'mythology', 'historical-...</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>sonnets</td>\n",
       "      <td>Produced by Paul Murray, Rénald Lévesque and t...</td>\n",
       "      <td>{'read-for-school', 'poetry', '20th-century', ...</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88</td>\n",
       "      <td>sonnets</td>\n",
       "      <td>Produced by Paul Murray, Rénald Lévesque and t...</td>\n",
       "      <td>{'read-for-school', 'poetry', '20th-century', ...</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147</td>\n",
       "      <td>persuasion</td>\n",
       "      <td>Produced by Sharon Partridge and Martin Ward. ...</td>\n",
       "      <td>{'romance', 'literary-fiction', 'classics', 'h...</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                    title  \\\n",
       "0          31  the power and the glory   \n",
       "1          32                 paradise   \n",
       "2          88                  sonnets   \n",
       "3          88                  sonnets   \n",
       "4         147               persuasion   \n",
       "\n",
       "                                                text  \\\n",
       "0  Produced by Juliet Sutherland, Sjaani and PG D...   \n",
       "1  Produced by Judith Smith and Natalie Salter\\n\\...   \n",
       "2  Produced by Paul Murray, Rénald Lévesque and t...   \n",
       "3  Produced by Paul Murray, Rénald Lévesque and t...   \n",
       "4  Produced by Sharon Partridge and Martin Ward. ...   \n",
       "\n",
       "                                              genres language_code  \n",
       "0  {'literary-fiction', 'christian', 'history', '...           eng  \n",
       "1  {'literary-fiction', 'mythology', 'historical-...           eng  \n",
       "2  {'read-for-school', 'poetry', '20th-century', ...           eng  \n",
       "3  {'read-for-school', 'poetry', '20th-century', ...           eng  \n",
       "4  {'romance', 'literary-fiction', 'classics', 'h...           eng  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = raw_data.sample(2)\n",
    "dev_data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "###Creating a validation set\n",
    "val_data = raw_data.sample(1)\n",
    "val_data.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>genres</th>\n",
       "      <th>language_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>germinal</td>\n",
       "      <td>This eBook was produced by Carlo Traverso.\\n\\n...</td>\n",
       "      <td>{'romance', 'literary-fiction', 'history', 'ro...</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>frankenstein</td>\n",
       "      <td>Produced by Judith Boss, Christy Phillips, Lyn...</td>\n",
       "      <td>{'horror', 'mystery', 'classics', 'supernatura...</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title                                               text  \\\n",
       "391      germinal  This eBook was produced by Carlo Traverso.\\n\\n...   \n",
       "388  frankenstein  Produced by Judith Boss, Christy Phillips, Lyn...   \n",
       "\n",
       "                                                genres language_code  \n",
       "391  {'romance', 'literary-fiction', 'history', 'ro...           eng  \n",
       "388  {'horror', 'mystery', 'classics', 'supernatura...         en-US  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>genres</th>\n",
       "      <th>language_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>the aeneid</td>\n",
       "      <td>19 BC\\n\\n  THE AENEID\\n\\n  by Virgil\\n\\n\\n  ...</td>\n",
       "      <td>{'adventure', 'history', 'mythology', 'histori...</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          title                                               text  \\\n",
       "212  the aeneid    19 BC\\n\\n  THE AENEID\\n\\n  by Virgil\\n\\n\\n  ...   \n",
       "\n",
       "                                                genres language_code  \n",
       "212  {'adventure', 'history', 'mythology', 'histori...           eng  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\setul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\setul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    Function to clean text of books. Removes email addresses, new lines, html tags, and extra spaces.\n",
    "\n",
    "    Input: Text (String)\n",
    "    Output: Cleaned Text (String)\n",
    "    '''\n",
    "    cleaned_text = text.lower()\n",
    "    cleaned_text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', ' ', text)\n",
    "    cleaned_text = re.sub(r'^.*?(?=\\n\\n\\n)', ' ', cleaned_text, flags=re.DOTALL)\n",
    "    cleaned_text = re.sub(r'<a\\s+(?:[^>]*?\\s+)?href=\"([^\"]*)\"[^>]*>.*?</a>', ' ', cleaned_text, flags=re.DOTALL)\n",
    "    cleaned_text = re.sub(r'\\n', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\d+', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'[^\\w\\s.?!]', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r' +', ' ', cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_first_row(group):\n",
    "    return group.iloc[1:]\n",
    "\n",
    "def lowercase(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data['cleaned_text'] = dev_data['text'].apply(lambda x:clean_text(x))\n",
    "dev_data.loc[:,'genres'] = dev_data.loc[:,'genres'].apply(lambda x:clean_text(x))\n",
    "dev_data.loc[:,'sentences'] = dev_data.loc[:,'cleaned_text'].apply(lambda x: nltk.tokenize.sent_tokenize(str(x)))\n",
    "dev_data = dev_data.explode('sentences')\n",
    "dev_data.loc[:,'sentences'] = dev_data.loc[:,'sentences'].apply(lambda x:lowercase(x))\n",
    "dev_data.reset_index(drop=True, inplace=True)\n",
    "dev_data['label_sentences'] = dev_data.groupby('title')['sentences'].shift(-1)\n",
    "dev_data = dev_data.dropna(subset=['label_sentences'])\n",
    "dev_data = dev_data.loc[:,['title', 'genres','sentences', 'label_sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data['cleaned_text'] = val_data['text'].apply(lambda x:clean_text(x))\n",
    "val_data.loc[:,'genres'] = val_data.loc[:,'genres'].apply(lambda x:clean_text(x))\n",
    "val_data.loc[:,'sentences'] = val_data.loc[:,'cleaned_text'].apply(lambda x: nltk.tokenize.sent_tokenize(str(x)))\n",
    "val_data = val_data.explode('sentences')\n",
    "val_data.loc[:,'sentences'] = val_data.loc[:,'sentences'].apply(lambda x:lowercase(x))\n",
    "val_data.reset_index(drop=True, inplace=True)\n",
    "val_data['label_sentences'] = val_data.groupby('title')['sentences'].shift(-1)\n",
    "val_data = val_data.dropna(subset=['label_sentences'])\n",
    "val_data = val_data.loc[:,['title', 'genres','sentences', 'label_sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>sentences</th>\n",
       "      <th>label_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>germinal</td>\n",
       "      <td>romance literary fiction history roman classi...</td>\n",
       "      <td>author émile zola title germinal remark n. of...</td>\n",
       "      <td>nous remercions la bibliothèque nationale de f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>germinal</td>\n",
       "      <td>romance literary fiction history roman classi...</td>\n",
       "      <td>nous remercions la bibliothèque nationale de f...</td>\n",
       "      <td>émile zola germinal première partie i dans la ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>germinal</td>\n",
       "      <td>romance literary fiction history roman classi...</td>\n",
       "      <td>émile zola germinal première partie i dans la ...</td>\n",
       "      <td>devant lui il ne voyait même pas le sol noir e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>germinal</td>\n",
       "      <td>romance literary fiction history roman classi...</td>\n",
       "      <td>devant lui il ne voyait même pas le sol noir e...</td>\n",
       "      <td>aucune ombre d arbre ne tachait le ciel le pav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>germinal</td>\n",
       "      <td>romance literary fiction history roman classi...</td>\n",
       "      <td>aucune ombre d arbre ne tachait le ciel le pav...</td>\n",
       "      <td>l homme était parti de marchiennes vers deux h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      title                                             genres  \\\n",
       "0  germinal   romance literary fiction history roman classi...   \n",
       "1  germinal   romance literary fiction history roman classi...   \n",
       "2  germinal   romance literary fiction history roman classi...   \n",
       "3  germinal   romance literary fiction history roman classi...   \n",
       "4  germinal   romance literary fiction history roman classi...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0   author émile zola title germinal remark n. of...   \n",
       "1  nous remercions la bibliothèque nationale de f...   \n",
       "2  émile zola germinal première partie i dans la ...   \n",
       "3  devant lui il ne voyait même pas le sol noir e...   \n",
       "4  aucune ombre d arbre ne tachait le ciel le pav...   \n",
       "\n",
       "                                     label_sentences  \n",
       "0  nous remercions la bibliothèque nationale de f...  \n",
       "1  émile zola germinal première partie i dans la ...  \n",
       "2  devant lui il ne voyait même pas le sol noir e...  \n",
       "3  aucune ombre d arbre ne tachait le ciel le pav...  \n",
       "4  l homme était parti de marchiennes vers deux h...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data = dev_data.loc[:,['title', 'genres','sentences', 'label_sentences']]\n",
    "dev_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>sentences</th>\n",
       "      <th>label_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the aeneid</td>\n",
       "      <td>adventure history mythology historical fictio...</td>\n",
       "      <td>book i arms and the man i sing who forc d by ...</td>\n",
       "      <td>long labors both by sea and land he bore and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the aeneid</td>\n",
       "      <td>adventure history mythology historical fictio...</td>\n",
       "      <td>long labors both by sea and land he bore and i...</td>\n",
       "      <td>o muse!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the aeneid</td>\n",
       "      <td>adventure history mythology historical fictio...</td>\n",
       "      <td>o muse!</td>\n",
       "      <td>the causes and the crimes relate what goddess ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the aeneid</td>\n",
       "      <td>adventure history mythology historical fictio...</td>\n",
       "      <td>the causes and the crimes relate what goddess ...</td>\n",
       "      <td>can heav nly minds such high resentment show o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the aeneid</td>\n",
       "      <td>adventure history mythology historical fictio...</td>\n",
       "      <td>can heav nly minds such high resentment show o...</td>\n",
       "      <td>against the tiber s mouth but far away an anci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        title                                             genres  \\\n",
       "0  the aeneid   adventure history mythology historical fictio...   \n",
       "1  the aeneid   adventure history mythology historical fictio...   \n",
       "2  the aeneid   adventure history mythology historical fictio...   \n",
       "3  the aeneid   adventure history mythology historical fictio...   \n",
       "4  the aeneid   adventure history mythology historical fictio...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0   book i arms and the man i sing who forc d by ...   \n",
       "1  long labors both by sea and land he bore and i...   \n",
       "2                                            o muse!   \n",
       "3  the causes and the crimes relate what goddess ...   \n",
       "4  can heav nly minds such high resentment show o...   \n",
       "\n",
       "                                     label_sentences  \n",
       "0  long labors both by sea and land he bore and i...  \n",
       "1                                            o muse!  \n",
       "2  the causes and the crimes relate what goddess ...  \n",
       "3  can heav nly minds such high resentment show o...  \n",
       "4  against the tiber s mouth but far away an anci...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data = val_data.loc[:,['title', 'genres','sentences', 'label_sentences']]\n",
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pour surcroît de chance grâce à des protections la compagnie l avait autorisée à vendre des bonbons et des biscuits dont elle étalait les bocaux sur deux planches derrière les vitres de la fenêtre.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data.loc[1905, 'sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Building vocabulary original and functional\n",
    "# from torchtext.data.utils import get_tokenizer\n",
    "# from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "# tokenizer = get_tokenizer('basic_english')\n",
    "# vocab_iter = iter(dev_data.loc[:,'sentences'] + dev_data.loc[:,'title'] + dev_data.loc[:,'genres'])\n",
    "# def yield_tokens(train_iter):\n",
    "#     for text in train_iter:\n",
    "#         if not isinstance(text, str):\n",
    "#             if type(text) == list:\n",
    "#                 for t in text:\n",
    "#                     yield tokenizer(t)\n",
    "#             continue\n",
    "#         yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building vocabulary fixed\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab_iter = iter(dev_data.loc[:,'sentences'])\n",
    "def yield_tokens(train_iter):\n",
    "    for text in train_iter:\n",
    "        if not isinstance(text, str):\n",
    "            if type(text) == list:\n",
    "                for t in text:\n",
    "                    yield tokenizer(t)\n",
    "            continue\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(vocab_iter), specials=[\"<unk>\", \"<pad>\", \"<BOS>\", \"<EOS>\"], min_freq=50)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_CACHE_DIR = '/Users/setul/mlpp23/.vector_cache'\n",
    "glove = torchtext.vocab.GloVe('6B', cache=VECTOR_CACHE_DIR)\n",
    "glove_vectors = glove.get_vecs_by_tokens(vocab.get_itos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>sentences</th>\n",
       "      <th>label_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>germinal</td>\n",
       "      <td>romance literary fiction history roman classi...</td>\n",
       "      <td>mais cela les égayait d être ainsi de songer à...</td>\n",
       "      <td>a réquillart ils s asseyaient sur une poutre c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>germinal</td>\n",
       "      <td>romance literary fiction history roman classi...</td>\n",
       "      <td>a réquillart ils s asseyaient sur une poutre c...</td>\n",
       "      <td>sans doute ils redevenaient jeunes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>germinal</td>\n",
       "      <td>romance literary fiction history roman classi...</td>\n",
       "      <td>sans doute ils redevenaient jeunes.</td>\n",
       "      <td>autour d eux des galants troussaient leurs amo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>germinal</td>\n",
       "      <td>romance literary fiction history roman classi...</td>\n",
       "      <td>autour d eux des galants troussaient leurs amo...</td>\n",
       "      <td>c était déjà derrière la fosse quarante trois ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>germinal</td>\n",
       "      <td>romance literary fiction history roman classi...</td>\n",
       "      <td>c était déjà derrière la fosse quarante trois ...</td>\n",
       "      <td>ah!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>germinal</td>\n",
       "      <td>romance literary fiction history roman classi...</td>\n",
       "      <td>ah!</td>\n",
       "      <td>il y avait beau temps!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title                                             genres  \\\n",
       "2480  germinal   romance literary fiction history roman classi...   \n",
       "2481  germinal   romance literary fiction history roman classi...   \n",
       "2482  germinal   romance literary fiction history roman classi...   \n",
       "2483  germinal   romance literary fiction history roman classi...   \n",
       "2484  germinal   romance literary fiction history roman classi...   \n",
       "2485  germinal   romance literary fiction history roman classi...   \n",
       "\n",
       "                                              sentences  \\\n",
       "2480  mais cela les égayait d être ainsi de songer à...   \n",
       "2481  a réquillart ils s asseyaient sur une poutre c...   \n",
       "2482                sans doute ils redevenaient jeunes.   \n",
       "2483  autour d eux des galants troussaient leurs amo...   \n",
       "2484  c était déjà derrière la fosse quarante trois ...   \n",
       "2485                                                ah!   \n",
       "\n",
       "                                        label_sentences  \n",
       "2480  a réquillart ils s asseyaient sur une poutre c...  \n",
       "2481                sans doute ils redevenaient jeunes.  \n",
       "2482  autour d eux des galants troussaient leurs amo...  \n",
       "2483  c était déjà derrière la fosse quarante trois ...  \n",
       "2484                                                ah!  \n",
       "2485                             il y avait beau temps!  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data.iloc[2480:2486]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "IS_CUDA = torch.cuda.is_available()\n",
    "if IS_CUDA:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def collate_batch(batch):\n",
    "    titles, genres, sentences, label_sentences = zip(*batch)\n",
    "    #Add a separator tag between title and genre\n",
    "    context = [tokenizer(g) + ['<pad>'] + tokenizer(t) + ['<pad>'] +\n",
    "               ['<BOS>'] + tokenizer(s) + ['<EOS>'] for t, g,\n",
    "                s in zip(titles, genres, sentences)]\n",
    "    label_sentence = [['<BOS>'] + tokenizer(s) + ['<EOS>'] for s in label_sentences]\n",
    "    label_tensor = pad_sequence([torch.tensor(vocab.lookup_indices(t)) for t in label_sentence],\n",
    "                                    padding_value=vocab['<pad>'], batch_first=True)\n",
    "    encoder_tensor = pad_sequence([torch.tensor(vocab.lookup_indices(t)) for t in context],\n",
    "                                 padding_value=vocab['<pad>'], batch_first=True)\n",
    "    return encoder_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From HW4\n",
    "from torch.utils.data import Sampler\n",
    "class BatchSequentialSampler(Sampler):\n",
    "    r\"\"\"Samples batches, s.t. the ith elements of each batch are sequential.\n",
    "\n",
    "    Args:\n",
    "        data_source (Dataset): dataset to sample from\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_source, batch_size):\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __iter__(self):\n",
    "        num_batches = len(self.data_source)//self.batch_size\n",
    "        for i in range(num_batches):\n",
    "            for j in range(self.batch_size):\n",
    "                yield(j * num_batches + i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.data_source)//self.batch_size) * self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sampler = BatchSequentialSampler(dev_data.loc[:,['title', 'genres', 'sentences', 'label_sentences']], 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dataloader = torch.utils.data.DataLoader(dev_data.loc[:,['title', 'genres', 'sentences', 'label_sentences']].values,\n",
    "                                                   batch_size=32, collate_fn=collate_batch, sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sampler = BatchSequentialSampler(val_data.loc[:,['title', 'genres', 'sentences', 'label_sentences']], 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = torch.utils.data.DataLoader(val_data.loc[:,['title', 'genres', 'sentences', 'label_sentences']].values,\n",
    "                                                   batch_size=32, collate_fn=collate_batch, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 68])\n",
      "torch.Size([32, 51])\n"
     ]
    }
   ],
   "source": [
    "for idx, (context_tensor, label_tensor) in enumerate(batch_dataloader):\n",
    "    print(context_tensor.shape)\n",
    "    print(label_tensor.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN_encoder(nn.Module):\n",
    "    def __init__ (self, embedding_dim, hidden_dim,\n",
    "                  vocab_size, num_layers=2, type_rnn = 'LSTM', bidirectional = True,\n",
    "                  dropout = 0.3, pad_idx = 0):\n",
    "        super(BiRNN_encoder, self).__init__()\n",
    "        self.rnns = []\n",
    "        # self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx).to(device)\n",
    "        self.embedding = nn.Embedding.from_pretrained(glove_vectors, freeze=False).to(device)\n",
    "        hidden_size = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "        input_size = embedding_dim\n",
    "        for _ in range(num_layers):\n",
    "            if type_rnn == 'LSTM':\n",
    "                rnn = nn.LSTM(input_size, hidden_size, 1, dropout = dropout,\n",
    "                               bidirectional = bidirectional, batch_first=True).to(device)\n",
    "            elif type_rnn == 'GRU':\n",
    "                rnn = nn.GRU(input_size, hidden_size, 1, dropout = dropout,\n",
    "                              bidirectional = bidirectional, batch_first=True).to(device)\n",
    "            self.rnns.append(rnn)\n",
    "            input_size = hidden_size*2 if bidirectional else hidden_size\n",
    "        self.rnns = nn.ModuleList(self.rnns).to(device)\n",
    "        self.dropout = nn.Dropout(dropout).to(device)\n",
    "        self.type_rnn = type_rnn\n",
    "        self.bidirectional = bidirectional\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, input, hidden = None):\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.dropout(embedded)\n",
    "        rnn_input = embedded\n",
    "        for idx, rnn in enumerate(self.rnns):\n",
    "            output, hidden_output = rnn(rnn_input, hidden)\n",
    "            hidden = hidden_output\n",
    "            rnn_input = output\n",
    "        if self.type_rnn == 'LSTM' and self.bidirectional:\n",
    "            hidden_state = torch.cat((hidden[0][-2,:,:], hidden[0][-1,:,:]), dim = 1).to(device)\n",
    "            cell = torch.cat((hidden[1][-2,:,:], hidden[1][-1,:,:]), dim = 1).to(device)\n",
    "            hidden = (hidden_state, cell)\n",
    "        elif self.type_rnn == 'GRU' and self.bidirectional:\n",
    "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1).to(device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\setul\\miniconda3\\envs\\talk-berty\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "encoder = BiRNN_encoder(300, 600, len(vocab), num_layers=3, type_rnn = 'LSTM',\n",
    "                         bidirectional = True, dropout = 0.3, pad_idx = vocab['<pad>']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2400])\n",
      "torch.Size([32, 2400])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(batch_dataloader):\n",
    "    context_tensor, label_tensor = batch\n",
    "    context_tensor, label_tensor = context_tensor.to(device), label_tensor.to(device)\n",
    "    hidden,cell = encoder(context_tensor)\n",
    "    print(hidden.shape)\n",
    "    print(cell.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN_decoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_layers, vocab_dim, dropout = 0.3):\n",
    "        super(BiRNN_decoder, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.vocab_dim = vocab_dim\n",
    "        self.dropout = nn.Dropout(dropout).to(device)\n",
    "        # self.embedding = nn.Embedding(vocab_dim, embedding_dim).to(device)\n",
    "        self.embedding = nn.Embedding.from_pretrained(glove_vectors, freeze=False).to(device)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers, dropout = dropout).to(device)\n",
    "        self.fc_out = nn.Linear(hidden_dim, vocab_dim).to(device)\n",
    "\n",
    "\n",
    "    def forward(self, input, hidden, context):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        outputs, (hidden,context) = self.rnn(embedded, (hidden, context))\n",
    "        predictions = self.fc_out(outputs)\n",
    "        predictions = predictions.squeeze(0)\n",
    "        return predictions, hidden, context\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = BiRNN_decoder(300, 2400, 1, len(vocab), dropout = 0.3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, src, trg, hidden, teacher_ratio = 0.5):\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = len(vocab)\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(device)\n",
    "        hidden, context = self.encoder(src, hidden)\n",
    "        # hidden = hidden.detach()\n",
    "        # context = context.detach()\n",
    "        dec_input = trg[:, 0]\n",
    "        dec_input = dec_input.unsqueeze(0)\n",
    "        hidden = hidden.unsqueeze(0)\n",
    "        context = context.unsqueeze(0)\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, context = self.decoder(dec_input, hidden, context)\n",
    "            outputs[t] = output\n",
    "            top1 = output.argmax(1)\n",
    "            dec_input = trg[:,t] if np.random.random() < teacher_ratio else top1\n",
    "            dec_input = dec_input.unsqueeze(0)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader):\n",
    "    '''\n",
    "    Evaluate the model on the given data.\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "    it = iter(data_loader)\n",
    "    total_count = 0. # Number of target words seen\n",
    "    total_loss = 0. # Loss over all target words\n",
    "    with torch.no_grad():\n",
    "        # No gradients need to be maintained during evaluation\n",
    "        # There are no hidden tensors for the first batch, and so will default to zeros.\n",
    "        hidden = None \n",
    "        for i, batch in enumerate(it):\n",
    "            text, target = batch\n",
    "            text, target = text.to(device), target.to(device)\n",
    "            output = model(text, target, hidden).to(device)\n",
    "            mask = (target != PAD_IDX)\n",
    "            ntotal = mask.sum()\n",
    "            loss = loss_fn(output.view(-1, output.size(-1)), target.view(-1))\n",
    "            total_count += ntotal\n",
    "            total_loss += loss.item()/ntotal\n",
    "                \n",
    "    # loss = total_loss / total_count\n",
    "    model.train()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##ChatGPT's improvement\n",
    "# def evaluate(model, data_loader):\n",
    "#     model.eval()\n",
    "#     total_loss = 0.0\n",
    "#     total_count = 0  # Total number of non-<pad> tokens\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for text, target in data_loader:\n",
    "#             if USE_CUDA:\n",
    "#                 text, target = text.cuda(), target.cuda()\n",
    "\n",
    "#             output = model(text, target)\n",
    "#             mask = (target != PAD_IDX)  # Create a mask for non-pad tokens\n",
    "#             ntotal = mask.sum().item()  # Sum the mask values to get the total number of non-<pad> tokens\n",
    "\n",
    "#             # Apply mask to filter out loss contributions from <pad> tokens and compute the loss\n",
    "#             loss = loss_fn(output.view(-1, output.size(-1)), target.view(-1))\n",
    "#             loss = loss.masked_select(mask.view(-1)).mean()  # Only consider non-<pad> tokens and compute mean loss\n",
    "            \n",
    "#             total_loss += loss.item() * ntotal  # Accumulate the total loss\n",
    "#             total_count += ntotal  # Accumulate the total count of non-<pad> tokens\n",
    "\n",
    "#     average_loss = total_loss / total_count  # Compute the average loss over all non-<pad> tokens\n",
    "#     model.train()\n",
    "#     return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iter 0 loss 3880.988525390625\n"
     ]
    }
   ],
   "source": [
    "LOG_FILE = \"language-model.log\"\n",
    "GRAD_CLIP = 1.\n",
    "NUM_EPOCHS = 5\n",
    "PAD_IDX = vocab['<pad>']\n",
    "\n",
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "    if h is None:\n",
    "        return None\n",
    "    elif isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)\n",
    "    \n",
    "    \n",
    "seq_model = Seq2Seq(encoder, decoder).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index = PAD_IDX, reduction = 'sum') ## Used instead of NLLLoss.\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(seq_model.parameters(), lr=learning_rate)\n",
    "val_losses = []\n",
    "best_model = None\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    seq_model.train()\n",
    "    it = iter(batch_dataloader)\n",
    "    hidden = None\n",
    "    for i, batch in enumerate(it):\n",
    "        data, target = batch\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        hidden = repackage_hidden(hidden)\n",
    "        output = seq_model(data, target, hidden).to(device)\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[:,1:].reshape(-1)\n",
    "        optimizer.zero_grad()\n",
    "        mask = (target != PAD_IDX)\n",
    "        #ntotal = mask.sum()\n",
    "        loss = loss_fn(output, target)\n",
    "        # loss = loss[mask]\n",
    "        # loss = loss.mean()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(seq_model.parameters(), GRAD_CLIP)\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(\"epoch\", epoch, \"iter\", i, \"loss\", loss.item())\n",
    "\n",
    "        if i % 10000 == 0:\n",
    "            val_loss = evaluate(seq_model, val_dataloader)\n",
    "            with open(LOG_FILE, \"a\") as fout:\n",
    "                print(\"epoch: {}, iteration: {}\".format(epoch, i))\n",
    "                fout.write(\"epoch: {}, iteration: {}, perplexity: {}\\n\".format(epoch, i, val_loss))\n",
    "\n",
    "            # Save the model if the validation loss is the minimum so far\n",
    "            if len(val_losses) == 0 or val_loss < min(val_losses):\n",
    "                print(\"best model, val loss: \", val_loss)\n",
    "                # #best_model = copy.deepcopy(model)\n",
    "                # best_model = type(seq_model)(vocab_size, EMBEDDING_SIZE, EMBEDDING_SIZE, 2, dropout=0.5)\n",
    "                # if USE_CUDA:\n",
    "                #     best_model = best_model.cuda()\n",
    "                # best_model.load_state_dict(model.state_dict())\n",
    "\n",
    "                # with open(PATH + \"lm-best.th\", \"wb\") as fout:\n",
    "                #     torch.save(best_model.state_dict(), fout)\n",
    "            else:\n",
    "                learning_rate /= 4.\n",
    "                optimizer = torch.optim.Adam(seq_model.parameters(), lr=learning_rate)\n",
    "            val_losses.append(val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##From other sources\n",
    "# epoch_loss = 0.0\n",
    "# num_epochs = 10\n",
    "# best_loss = 999999\n",
    "# best_epoch = -1\n",
    "# sentence1 = \"Hello I am starting\"\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# criterion = nn.CrossEntropyLoss(ignore_index = vocab['<pad>'])\n",
    "# ts1 = []\n",
    "# for epoch in range(num_epochs):\n",
    "#   print(\"Epoch - {} / {}\".format(epoch+1, num_epochs))\n",
    "#   model.train(True)\n",
    "#   for batch_idx, batch in enumerate(batch_dataloader):\n",
    "#     input , target = batch\n",
    "#     input, target = input.to(device), target.to(device)\n",
    "#     output = model(input, target).to(device)\n",
    "#     output = output[1:].reshape(-1, output.shape[2])\n",
    "#     target = target[:,1:].reshape(-1)\n",
    "    \n",
    "#     optimizer.zero_grad()\n",
    "#     loss = criterion(output, target)\n",
    "#     loss.backward()\n",
    "\n",
    "#     # Clip gradient >1 to prevent exploding gradients\n",
    "#     torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "#     # Update the weights values using the gradients we calculated using bp \n",
    "#     optimizer.step()\n",
    "#     #step += 1\n",
    "#     epoch_loss += loss.item()\n",
    "#     #writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "\n",
    "#   if epoch_loss < best_loss:\n",
    "#     best_loss = epoch_loss\n",
    "#     best_epoch = epoch\n",
    "#     if ((epoch - best_epoch) >= 3):\n",
    "#       print(\"no improvement in 3 epochs, break\")\n",
    "#       break\n",
    "#   print(\"Epoch_Loss - {}\".format(loss.item()))\n",
    "#   print()\n",
    "  \n",
    "# print(epoch_loss / len(batch_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(seq_model.state_dict(), 'seq_model_3_layers.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('seq_model_functional.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, input_genre, input_title, input_text, max_length=10):\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize and prepare input text\n",
    "    input_tokens = (tokenizer(input_genre) + ['<pad>'] + tokenizer(input_title) + ['<pad>'] +\n",
    "    ['<BOS>'] + tokenizer(input_text) + ['<EOS>'])\n",
    "    input_indices = vocab.lookup_indices(input_tokens)\n",
    "    input_tensor = torch.tensor([input_indices], dtype=torch.long, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden, context = model.encoder(input_tensor)\n",
    "    decoder_input = torch.tensor([[vocab['<BOS>']]], device=device)  \n",
    "    output_indices = []\n",
    "    context = context.unsqueeze(0)\n",
    "    hidden = hidden.unsqueeze(0)\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        with torch.no_grad():\n",
    "            output, hidden, context = model.decoder(decoder_input, hidden, context)\n",
    "            output_probabilities = output.squeeze().softmax(dim = -1).to(device)\n",
    "            top1 = torch.multinomial(output_probabilities, 1)[0]\n",
    "            if top1.item() == vocab['<EOS>']:\n",
    "                break\n",
    "            output_indices.append(top1.item())\n",
    "            decoder_input = torch.tensor([[top1.item()]], device=device)  \n",
    "    output_tokens = [vocab.lookup_token(index) for index in output_indices]\n",
    "    return ' '.join(output_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, input_genre, input_title, input_text, max_length=10):\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize and prepare input text\n",
    "    input_tokens = (tokenizer(input_genre) + ['<pad>'] + tokenizer(input_title) + ['<pad>'] +\n",
    "    ['<BOS>'] + tokenizer(input_text) + ['<EOS>'])\n",
    "    input_indices = vocab.lookup_indices(input_tokens)\n",
    "    input_tensor = torch.tensor([input_indices], dtype=torch.long, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden, context = model.encoder(input_tensor)\n",
    "    decoder_input = torch.tensor([[vocab['<BOS>']]], device=device)  \n",
    "    output_indices = []\n",
    "    context = context.unsqueeze(0)\n",
    "    hidden = hidden.unsqueeze(0)\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        with torch.no_grad():\n",
    "            output, hidden, context = model.decoder(decoder_input, hidden, context)\n",
    "            output_probabilities = output.squeeze().softmax(dim = -1).to(device)\n",
    "            #top1 = torch.multinomial(output_probabilities, 1)[0]\n",
    "            topk_values, topk_indices = torch.topk(output_probabilities, k=10)\n",
    "            # print(topk_values)\n",
    "            # print(topk_indices)\n",
    "            top1 = torch.multinomial(topk_values, 1)[0]\n",
    "            if top1.item() == vocab['<BOS>'] or top1.item() ==vocab['<unk>'] or top1.item() ==vocab['<pad>']:\n",
    "                continue\n",
    "            if top1.item() == vocab['<EOS>'] and len(output_indices) >3:\n",
    "                break\n",
    "            elif top1.item() == vocab['<EOS>']:\n",
    "                continue\n",
    "            output_indices.append(top1.item())\n",
    "            decoder_input = torch.tensor([[top1.item()]], device=device)  \n",
    "    output_tokens = [vocab.lookup_token(index) for index in output_indices]\n",
    "    return ' '.join(output_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_title = \"the game\"\n",
    "input_genre = \"fiction\"\n",
    "input_sentence = \"he saw a line.\"\n",
    "generated_text = generate_text(seq_model, input_genre, input_title, input_sentence, max_length=50)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in seq_model.parameters():\n",
    "    print(\"param\", param.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "talk-berty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
