{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKOTlwcmxmej"
   },
   "source": [
    "# GPT-2 Fine-Tuning\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xf3Qw77SZGbS"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12544,
     "status": "ok",
     "timestamp": 1709781289939,
     "user": {
      "displayName": "Eshan Prashar",
      "userId": "03910558186089522689"
     },
     "user_tz": 360
    },
    "id": "0NmMdkZO8R6q",
    "outputId": "9a0ad25b-6f7e-4ddf-c032-defadbc06ef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/b6/4d/fbe6d89fde59d8107f0a02816c4ac4542a8f9a85559fdf33c68282affcc1/transformers-4.38.2-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from transformers) (3.12.2)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.19.3 from https://files.pythonhosted.org/packages/ab/28/d4b691840d73126d4c9845f8a22dad033ac872509b6d3a0d93b456eef424/huggingface_hub-0.21.4-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/eb/10/4ccc8eed80f11c082a2883d49d4090aa80c7f65704216a529f490cb089b1/regex-2023.12.25-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached regex-2023.12.25-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Obtaining dependency information for tokenizers<0.19,>=0.14 from https://files.pythonhosted.org/packages/0e/d7/3220a4483d240180d0b9423206cc57a4997fd4b49a8393e5ce9a2f7908a9/tokenizers-0.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached tokenizers-0.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Obtaining dependency information for safetensors>=0.4.1 from https://files.pythonhosted.org/packages/50/7f/8f6dd5b16cdc9efb01ea6169037c2b4a1e3b433baae78ab14c0f8f88f012/safetensors-0.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached safetensors-0.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from transformers) (4.65.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers)\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/ad/30/2281c062222dc39328843bd1ddd30ff3005ef8e30b2fd09c4d2792766061/fsspec-2024.2.0-py3-none-any.whl.metadata\n",
      "  Using cached fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests->transformers) (2023.7.22)\n",
      "Using cached transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "Using cached huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "Using cached regex-2023.12.25-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (777 kB)\n",
      "Using cached safetensors-0.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached tokenizers-0.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Using cached fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "Installing collected packages: safetensors, regex, fsspec, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed fsspec-2024.2.0 huggingface-hub-0.21.4 regex-2023.12.25 safetensors-0.4.2 tokenizers-0.15.2 transformers-4.38.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17891,
     "status": "ok",
     "timestamp": 1709781313484,
     "user": {
      "displayName": "Eshan Prashar",
      "userId": "03910558186089522689"
     },
     "user_tz": 360
    },
    "id": "JCCeyhuDHdOu",
    "outputId": "6287fb65-bbcd-4457-c130-cb13b48abf5e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfdCML6Parvv"
   },
   "source": [
    "# Create Training Set\n",
    "\n",
    "The data used to finetune the language model is a set of around 1000 DJ biographies, with the aim of generating them in the same general format and style.\n",
    "\n",
    "This data isn't public so if you want to use this script, you'll have to source your own training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23044,
     "status": "ok",
     "timestamp": 1709781347716,
     "user": {
      "displayName": "Eshan Prashar",
      "userId": "03910558186089522689"
     },
     "user_tz": 360
    },
    "id": "_EYFrNxr-TYb",
    "outputId": "73ab5c5e-c5f4-498c-855f-c16db55a421c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/sagemaker-studiolab-notebooks\n"
     ]
    }
   ],
   "source": [
    "# path of the directory\n",
    "dir_path = os.getcwd()\n",
    "print(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 16972,
     "status": "ok",
     "timestamp": 1709781366395,
     "user": {
      "displayName": "Eshan Prashar",
      "userId": "03910558186089522689"
     },
     "user_tz": 360
    },
    "id": "G_DWAMe1FopX"
   },
   "outputs": [],
   "source": [
    "# Reading the new training data file\n",
    "data_gutenberg_full = pd.read_csv(dir_path+'/books_and_genres_eng.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1709781368831,
     "user": {
      "displayName": "Eshan Prashar",
      "userId": "03910558186089522689"
     },
     "user_tz": 360
    },
    "id": "QXF2xXgrtQqW",
    "outputId": "1ec4419a-d1c4-4aef-8631-71bfe6855aa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset are: ['Unnamed: 0', 'title', 'text', 'genres', 'language_code']\n",
      "Number of books: 232\n",
      "Let's look at first 5 random rows of the dataset\n",
      "   Unnamed: 0                    title  \\\n",
      "0          31  the power and the glory   \n",
      "1          32                 paradise   \n",
      "2          88                  sonnets   \n",
      "3          88                  sonnets   \n",
      "4         147               persuasion   \n",
      "\n",
      "                                                text  \\\n",
      "0  Produced by Juliet Sutherland, Sjaani and PG D...   \n",
      "1  Produced by Judith Smith and Natalie Salter\\n\\...   \n",
      "2  Produced by Paul Murray, Rénald Lévesque and t...   \n",
      "3  Produced by Paul Murray, Rénald Lévesque and t...   \n",
      "4  Produced by Sharon Partridge and Martin Ward. ...   \n",
      "\n",
      "                                              genres language_code  \n",
      "0  {'literary-fiction', 'christian', 'history', '...           eng  \n",
      "1  {'literary-fiction', 'mythology', 'historical-...           eng  \n",
      "2  {'read-for-school', 'poetry', '20th-century', ...           eng  \n",
      "3  {'read-for-school', 'poetry', '20th-century', ...           eng  \n",
      "4  {'romance', 'literary-fiction', 'classics', 'h...           eng  \n"
     ]
    }
   ],
   "source": [
    "# Examining the larger set of books\n",
    "print(f\"Columns in dataset are: {data_gutenberg_full.columns.to_list()}\")\n",
    "print(f\"Number of books: {len(data_gutenberg_full['title'].unique())}\")\n",
    "print(\"Let's look at first 5 random rows of the dataset\")\n",
    "print(data_gutenberg_full.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1709781373940,
     "user": {
      "displayName": "Eshan Prashar",
      "userId": "03910558186089522689"
     },
     "user_tz": 360
    },
    "id": "LL2XSLh6tiyq",
    "outputId": "d798ba8a-287f-4833-e385-538562f4e555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0                    title  \\\n",
      "0            31  the power and the glory   \n",
      "1            32                 paradise   \n",
      "2            88                  sonnets   \n",
      "3            88                  sonnets   \n",
      "4           147               persuasion   \n",
      "..          ...                      ...   \n",
      "437       10126          a modern utopia   \n",
      "438       10136    the mill on the floss   \n",
      "439       10136    the mill on the floss   \n",
      "440       10212           piccadilly jim   \n",
      "441       10363                sanctuary   \n",
      "\n",
      "                                                  text  \\\n",
      "0    Produced by Juliet Sutherland, Sjaani and PG D...   \n",
      "1    Produced by Judith Smith and Natalie Salter\\n\\...   \n",
      "2    Produced by Paul Murray, Rénald Lévesque and t...   \n",
      "3    Produced by Paul Murray, Rénald Lévesque and t...   \n",
      "4    Produced by Sharon Partridge and Martin Ward. ...   \n",
      "..                                                 ...   \n",
      "437  Produced by Andrew Sly\\n\\n\\n\\n\\n\\n\\nA MODERN U...   \n",
      "438  Produced by Curtis Weyant and David Maddock\\n\\...   \n",
      "439  Produced by Curtis Weyant and David Maddock\\n\\...   \n",
      "440  Etext produced by Jim Tinsley <jtinsley@pobox....   \n",
      "441  Charles Aldarondo, Tiffany Vergon, William Fli...   \n",
      "\n",
      "                                                genres language_code  \n",
      "0    {'literary-fiction', 'christian', 'history', '...           eng  \n",
      "1    {'literary-fiction', 'mythology', 'historical-...           eng  \n",
      "2    {'read-for-school', 'poetry', '20th-century', ...           eng  \n",
      "3    {'read-for-school', 'poetry', '20th-century', ...           eng  \n",
      "4    {'romance', 'literary-fiction', 'classics', 'h...           eng  \n",
      "..                                                 ...           ...  \n",
      "437  {'classics', 'non-fiction', 'science-fiction',...           eng  \n",
      "438  {'romance', 'literary-fiction', 'classics', 'f...           eng  \n",
      "439  {'romance', 'literary-fiction', 'classics', 'f...           eng  \n",
      "440  {'romance', 'classics', 'novels', 'literature'...           eng  \n",
      "441  {'romance', 'contemporary', 'crime', 'mystery'...           eng  \n",
      "\n",
      "[442 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Only retain the text and genre from the dataset\n",
    "gutenberg_full = data_gutenberg_full.drop(columns=['Unnamed: 0','title'])\n",
    "print(data_gutenberg_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1709781382068,
     "user": {
      "displayName": "Eshan Prashar",
      "userId": "03910558186089522689"
     },
     "user_tz": 360
    },
    "id": "D3uzXBRYf6cN",
    "outputId": "867d181b-8b53-468c-ca6f-7b160d9320c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing text\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    Function to clean text of books. Removes email addresses, new lines, html tags, and extra spaces.\n",
    "\n",
    "    Input: Text (String)\n",
    "    Output: Cleaned Text (String)\n",
    "    '''\n",
    "    cleaned_text = text.lower()\n",
    "    cleaned_text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', ' ', text)\n",
    "    cleaned_text = re.sub(r'^.*?(?=\\n\\n\\n)', ' ', cleaned_text, flags=re.DOTALL)\n",
    "    cleaned_text = re.sub(r'<a\\s+(?:[^>]*?\\s+)?href=\"([^\"]*)\"[^>]*>.*?</a>', ' ', cleaned_text, flags=re.DOTALL)\n",
    "    cleaned_text = re.sub(r'\\n', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\d+', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'[^\\w\\s.?!]', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r' +', ' ', cleaned_text)\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_first_row(group):\n",
    "    return group.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 201,
     "output_embedded_package_id": "1pH6f-IKcCO_WuoEc96656BaYoK6mLuSd"
    },
    "executionInfo": {
     "elapsed": 66696,
     "status": "ok",
     "timestamp": 1709781455050,
     "user": {
      "displayName": "Eshan Prashar",
      "userId": "03910558186089522689"
     },
     "user_tz": 360
    },
    "id": "cg1Y9eLmt3ED",
    "outputId": "cf7552d9-5631-42c8-bb16-2e635793463c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>genres</th>\n",
       "      <th>language_code</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Produced by Juliet Sutherland, Sjaani and PG D...</td>\n",
       "      <td>literary fiction christian history classics r...</td>\n",
       "      <td>eng</td>\n",
       "      <td>the power and the glory by grace macgowan coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Produced by Judith Smith and Natalie Salter\\n\\...</td>\n",
       "      <td>literary fiction mythology historical fiction...</td>\n",
       "      <td>eng</td>\n",
       "      <td>the vision of hell purgatory and paradise by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Produced by Paul Murray, Rénald Lévesque and t...</td>\n",
       "      <td>read for school poetry th century reference</td>\n",
       "      <td>eng</td>\n",
       "      <td>note du transcripteur. ce document est tiré d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Produced by Paul Murray, Rénald Lévesque and t...</td>\n",
       "      <td>read for school poetry th century reference</td>\n",
       "      <td>eng</td>\n",
       "      <td>note du transcripteur. ce document est tiré d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Produced by Sharon Partridge and Martin Ward. ...</td>\n",
       "      <td>romance literary fiction classics historical ...</td>\n",
       "      <td>eng</td>\n",
       "      <td>persuasion by jane austen chapter sir walter ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Produced by Juliet Sutherland, Sjaani and PG D...   \n",
       "1  Produced by Judith Smith and Natalie Salter\\n\\...   \n",
       "2  Produced by Paul Murray, Rénald Lévesque and t...   \n",
       "3  Produced by Paul Murray, Rénald Lévesque and t...   \n",
       "4  Produced by Sharon Partridge and Martin Ward. ...   \n",
       "\n",
       "                                              genres language_code  \\\n",
       "0   literary fiction christian history classics r...           eng   \n",
       "1   literary fiction mythology historical fiction...           eng   \n",
       "2       read for school poetry th century reference            eng   \n",
       "3       read for school poetry th century reference            eng   \n",
       "4   romance literary fiction classics historical ...           eng   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0   the power and the glory by grace macgowan coo...  \n",
       "1   the vision of hell purgatory and paradise by ...  \n",
       "2   note du transcripteur. ce document est tiré d...  \n",
       "3   note du transcripteur. ce document est tiré d...  \n",
       "4   persuasion by jane austen chapter sir walter ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying the cleaning functions\n",
    "gutenberg_full['cleaned_text'] = gutenberg_full['text'].apply(lambda x:clean_text(x))\n",
    "gutenberg_full.loc[:,'genres'] = gutenberg_full.loc[:,'genres'].apply(lambda x:clean_text(x))\n",
    "gutenberg_full.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMml12FJGjPW"
   },
   "source": [
    "# GPT2 Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Z474sSC6oe7A"
   },
   "outputs": [],
   "source": [
    "# Load the GPT tokenizer.\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ex5O1eV-Pfct"
   },
   "source": [
    "# Building the GPT2Dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "U_XJVIetKN-h"
   },
   "outputs": [],
   "source": [
    "class GPT2Dataset(Dataset):\n",
    "\n",
    "  def __init__(self, dataframe, tokenizer, gpt2_type=\"gpt2\", max_length=768):\n",
    "\n",
    "    self.tokenizer = tokenizer\n",
    "    self.input_ids = []\n",
    "    self.attn_masks = []\n",
    "    genres = dataframe['genres'].tolist()\n",
    "    text = dataframe['cleaned_text'].tolist()\n",
    "    for idx, textbook in enumerate(text):\n",
    "      encodings_dict = tokenizer(genres[idx]+':'+ '<|startoftext|>'+ textbook + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "\n",
    "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.input_ids)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.input_ids[idx], self.attn_masks[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Building the custom dataset class for DataLoader that incorporates genre and text\n",
    "class GPT2DatasetCustom(Dataset):\n",
    "\n",
    "    def __init__(self, df, tokenizer, max_length=768):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            genres = row['genres']\n",
    "            cleaned_text = row['cleaned_text']\n",
    "            tokenized_segments = self.tokenize_with_genre(genres, cleaned_text, max_length)\n",
    "            for segment in tokenized_segments:\n",
    "                self.input_ids.append(torch.tensor(segment['input_ids']))\n",
    "                self.attn_masks.append(torch.tensor(segment['attention_mask']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx] \n",
    "\n",
    "    def tokenize_with_genre(self, genres, cleaned_text, max_length):\n",
    "        genre_tokens = self.tokenizer(genres)['input_ids']\n",
    "        #print(genre_tokens)\n",
    "        genre_length = len(genre_tokens)\n",
    "        text_length = max_length - genre_length  # Remaining length for text tokens\n",
    "\n",
    "        # Initialize list to store tokenized segments\n",
    "        combined_tokens = []\n",
    "        attention_masks = []\n",
    "\n",
    "        # Tokenize cleaned_text into chunks of length text_length\n",
    "        # NOTE: Contains a bunch of print statements for debugging purposes; remove before running\n",
    "        for i in range(0, len(cleaned_text), text_length):\n",
    "            #print(len(cleaned_text))\n",
    "            # Get a chunk of text\n",
    "            chunk = cleaned_text[i:i + text_length]\n",
    "            #print(chunk)\n",
    "            #print(len(chunk))\n",
    "\n",
    "            # Tokenize the chunk\n",
    "            text_tokens = self.tokenizer(chunk, truncation=True, max_length=text_length, padding=\"max_length\")['input_ids']\n",
    "            #print(text_tokens)\n",
    "\n",
    "            # Added for debugging purposes- remove from final code\n",
    "            #decoded_text = self.tokenizer.decode(text_tokens, skip_special_tokens=True)\n",
    "            #print(\"Decoded text:\", decoded_text)\n",
    "\n",
    "            # Combine genre tokens with text tokens\n",
    "            segment_tokens = genre_tokens + text_tokens\n",
    "\n",
    "            # Create attention mask\n",
    "            # Identify padding tokens and set attention to 0 for those tokens\n",
    "            padding_mask = [0 if token == self.tokenizer.pad_token_id else 1 for token in segment_tokens]\n",
    "\n",
    "            # Pad the attention mask to ensure it has the same length as segment_tokens\n",
    "            # padding_mask += [0] * (max_length - len(padding_mask))\n",
    "\n",
    "            # Add the combined tokens and attention mask to the lists\n",
    "            combined_tokens.append(segment_tokens)\n",
    "            attention_masks.append(padding_mask)\n",
    "\n",
    "        # print to check lengths\n",
    "        #print(len(combined_tokens))\n",
    "        #print(len(attention_masks))\n",
    "\n",
    "        # COMMENTING THIS OUT TO GET 1 tensor per row\n",
    "        # Pad the segments to ensure they all have the same length\n",
    "        #max_segment_length = max(map(len, combined_tokens))\n",
    "        #combined_tokens = [segment + [self.tokenizer.pad_token_id] * (max_segment_length - len(segment)) for segment in combined_tokens]\n",
    "\n",
    "        # Convert lists to tensors\n",
    "        #input_ids = torch.tensor(combined_tokens)\n",
    "        #attn_masks = torch.tensor(attention_masks)\n",
    "\n",
    "\n",
    "        # Return a list of dictionaries containing input_ids and attention_mask for each segment\n",
    "        tokenized_segments = [{'input_ids': segment, 'attention_mask': mask} for segment, mask in zip(combined_tokens, attention_masks)]\n",
    "        #print(tokenized_segments)\n",
    "        return tokenized_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "l5rCUUrMucwx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  397 training samples\n",
      "   45 validation samples\n"
     ]
    }
   ],
   "source": [
    "# Creating the full dataset\n",
    "dataset_full = GPT2Dataset(gutenberg_full, tokenizer, max_length=768)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = int(0.9 * len(dataset_full))\n",
    "val_size = len(dataset_full) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset_full, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "x0WeP5PREUuy"
   },
   "outputs": [],
   "source": [
    "# Create the DataLoaders for our training and validation datasets.\n",
    "# We'll take training samples in random order.\n",
    "batch_size = 2\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6TKgyUzPIQc"
   },
   "source": [
    "# Finetune GPT2 Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "executionInfo": {
     "elapsed": 9487,
     "status": "ok",
     "timestamp": 1709775972683,
     "user": {
      "displayName": "Eshan Prashar",
      "userId": "03910558186089522689"
     },
     "user_tz": 360
    },
    "id": "gFsCTp_mporB",
    "outputId": "79a47c67-3fae-4eb3-b3bf-fe8902486d8c"
   },
   "outputs": [],
   "source": [
    "# Using config from GPT2\n",
    "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
    "\n",
    "# instantiate the model\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
    "\n",
    "# this step is necessary ensure embeddings and model tokenizer are aligned\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device = torch.device(\"cuda\")\n",
    "model.cuda()\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pBEVY2PYSTXJ"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters from tutorials: optimize if time available\n",
    "epochs = 10\n",
    "learning_rate = 5e-4\n",
    "warmup_steps = 1e2\n",
    "epsilon = 1e-8\n",
    "\n",
    "# Defining step size and optimizer\n",
    "sample_every = 100\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                  lr = learning_rate,\n",
    "                  eps = epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-p0upAhhRiIx"
   },
   "outputs": [],
   "source": [
    "# Total number of training steps is [number of batches] x [number of epochs].\n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "# This changes the learning rate as the training loop progresses\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = warmup_steps,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gpt6tR83keZD"
   },
   "outputs": [],
   "source": [
    "# Format time\n",
    "def format_time(elapsed):\n",
    "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45118,
     "status": "ok",
     "timestamp": 1709776119844,
     "user": {
      "displayName": "Eshan Prashar",
      "userId": "03910558186089522689"
     },
     "user_tz": 360
    },
    "id": "vCPohrZ-CTWu",
    "outputId": "26a83abe-57e7-427b-95cf-b49fc16e4aa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    199. Loss: 3.8064138889312744.   Elapsed: 0:00:47.\n",
      "0:  bipartisan, anti-government and anti- law enmeshed in the history of the United States. http_ of them. http. no_of them. http. no_of them. http. no_in_ondon. http. no_in_ondon as_ american_nebulous_us. http. no_in_ondon as_ americans_nato. http_russian. http. no_in_ondon as_ american_nebulous_us. http. no_on_n. http. no_on_n. http. the_most_random_comer. http. no_on_n. http _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "  Average training loss: 9.15\n",
      "  Training epoch took: 0:01:35\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 5.85\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    199. Loss: 3.7533438205718994.   Elapsed: 0:00:47.\n",
      "0:  increasing the old one. to give me this opportunity of giving a very high ground on which to meet these young people. of course you won all three of them have never had the most difficult task of mine and it is that the most good of them but for a child. we are so long and so sure that they can. they have given us many opportunities for the most excellent use of these children with no disadvantage that it could be used the children. you are very sure that there is something to be said by the child as well as it should be. it is not difficult to learn how we shall go with such children. at the same time the whole time that children should be taught. for the good thing to do it they ought to be given. they must be very well trained to be able to teach their children a whole course of the the whole class of principles and to help them. the whole class are being taught by the guidance of the students of the teachers and by\n",
      "\n",
      "  Average training loss: 4.48\n",
      "  Training epoch took: 0:01:36\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 3.76\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    199. Loss: 3.2237935066223145.   Elapsed: 0:00:48.\n",
      "0: day and to core of a dactylons of the original by this and of the great great by the dum of the original mr. s. and the great mrs. buchler brothers and sisters of the second book at the end of the first century at their christian villa and at last the year after christian and of the great mr. buchler brothers. the book was sold at random by the chancery of the german police guilds and was delivered in two volumes to the mr. buchler brothers who wrote the first edition and by the chancery of the german police guilds. the second edition of the great mr. buchler s work was published at the close of the nineteenth century but was unfinished at the end of the nineteenth century. it was not until the beginning of the century that it was again collected. the second edition\n",
      "\n",
      "  Average training loss: 3.49\n",
      "  Training epoch took: 0:01:36\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 3.37\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    199. Loss: 2.7897400856018066.   Elapsed: 0:00:47.\n",
      "0:  Hang a place where you can best meet. you might get a chance to meet them on your own terms. you might get a glimpse at what will be the next chapter. but most of the people you know of don t understand why you need a place at the university to study a new science. you will not be able to afford it to come your own way. you will have a hard time figuring out how to go about it because there are already so many scientific problems in the world you need to deal with. you will see one problem in the next chapter. the professor won t tell you what you should do. tell him. and he will get tired. you are going to have to start anew in your own way. how do you do? a lot better than what you were used to. and what does he want you to do? to make up his mind? he is too busy. if you try teaching at university you will be making him waste a week and a day\n",
      "\n",
      "  Average training loss: 2.93\n",
      "  Training epoch took: 0:01:36\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 2.99\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    199. Loss: 3.57405161857605.   Elapsed: 0:00:47.\n",
      "0:  foods book with illustrations by charles dickens contents chapter i. a. p.c. ii. the stockholm stockholm chapter ii. a. p.c. iii. on stampegowan st. petersburg chapter iii. with which the title page of the book has been added chapter iv. in which the discussion of stockholm appears on page vii. the stockholm stockholm chapter viii. a. p.c. ix. stockholm stockholm chapter x. the stockholm stockholm chapter xi. an introduction to the book. a. p.c. ii. the stockholm stockholm is the most complete book on the part of the great publisher to the best of authorities in the field who are interested in reading this book and whose opinions on the subject matter are expressed in this manner. chapter i. a. p.c. iii. a. p.c. iv. in which the stockholm is compared with that of\n",
      "\n",
      "  Average training loss: 2.42\n",
      "  Training epoch took: 0:01:36\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 2.72\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    199. Loss: 1.886625051498413.   Elapsed: 0:00:47.\n",
      "0:  trail history classics religion reference literature fiction childrens adult non fiction  egypt iliad _reform_ _reform_ the egypt that we will call it by rome is the most successful in its history. since its founding it spread from the very cradle of its pharaon to become the centre of the world and to the most populous city in the western sky. the egypt was the first civilization to be modern in the land. the eastern empire of rome was founded on the site of the second godwin temple to the west where it now lies. the west empire included in its empire the pharaon and jaros which under the rule of the godwin were erected in the eleventh century of the eleventh century and the modern name beltenebros is the result of that long and successful attempt. to modernize and modernize the empire the east and west are mutually exclusive. they are both great powers and they are at the same time the sister cities\n",
      "\n",
      "  Average training loss: 2.02\n",
      "  Training epoch took: 0:01:36\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 2.51\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    199. Loss: 2.0912551879882812.   Elapsed: 0:00:47.\n",
      "0: intend literary fiction drama classics novella high school novels literature fiction philosophy th century school adult read for school unfinished classics war poetry  the odyssey rendered into english prose for the use of those who cannot read original by samuel butler preface to first edition this translation is intended to supplement an earlier work entitled the authoress of the odyssey which i published in. i have not intended to supplement it with all the books i have translated and have restored them from their original location in their original location in u.s. for which i could not give the entire odyssey for this translation. the odyssey was written for a school boy of twelve or thirteen years who lived at amsterdam and as i soon grew old enough to read and enjoy the original i began to wonder how his ideas had changed as he went on his way about life. i begin with the idea that everybody was going senile because there was so much promising material in the odyssey i could not get a copy of\n",
      "\n",
      "  Average training loss: 1.73\n",
      "  Training epoch took: 0:01:36\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 2.45\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    199. Loss: 0.9620369076728821.   Elapsed: 0:00:47.\n",
      "0:  surround science fiction philosophy fiction travel novels literature fiction adult non fiction historical college  the moon of darwin a travel companion by george warren the director of companies _by_ george warren_ _faye warren._ the moon of darwin is seen in the distance and its companion the marshes. the dwarf s glories of ivory rods and wove silk are marvelously reflected in the transient beauty of the sun and its broad disk just skirting the equator. the region on the left side of marshes slopes to the west and east with a low temperature barely venturing beneath the transient beauty of the north and east. on the right side of marshes is the undiscovered continent of the deep west through which the drifting cloud swimmered and clumped together through the drifting gloom. in its broad disk the sun never sets nor ages nor does it change its course nor ages nor does it change its course nor does it change its course along its ever reaching pole\n",
      "\n",
      "  Average training loss: 1.50\n",
      "  Training epoch took: 0:01:36\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 2.44\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    199. Loss: 0.6942958235740662.   Elapsed: 0:00:47.\n",
      "0:  reflex the roman eagle and the halter of the spear. and with these words he laid the ground without turning to it the place now called the sultan. and there he laid before the palace that ran round it the pavilion and the palace itself. thereupon the young nobles of alban fathers found their feet in the pavilion and were carried there by the large furrows of the surrounding forest. thereupon they sat before the watcher in silence and did not answer but step out of the palace door and step into it. ah! the queen of the hill! said one of the daughters of the late queen of saros a man who had fallen in love with the old queen of alban. ah! the old queen! she was as dark as a raven s wing and her fiery black eyes were like an illusory dream. the young nobles knitted their brows and their hearts cried in terror at the sight of their master and at the sight of his daughters. he\n",
      "\n",
      "  Average training loss: 1.34\n",
      "  Training epoch took: 0:01:36\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 2.42\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    199. Loss: 1.3799030780792236.   Elapsed: 0:00:47.\n",
      "0:  display middle grade classics animals fantasy novels literature fiction th century childrens young adult school realistic fiction coming of age  the illustrated children s classics _treasure island_ robert louis stevenson _illustrated by_ milo winter illustration gramercy books new york and london by milo winter illustration gramercy books new york and london illustrated children s classics _treasure island_ robert louis ste treasure island_ robert louis stevenson preface _to_ _the_ reader if you like your children s classics deep inside of themselves then you ought to give your own opinion of them. while all this book content is intended to supplement a small volume i which i published in full on the possessions of my late father louis at the age of fifteen. what i liked most was the little illustrations that were used to illustrate the treasure island robert louis stevenson s treasure island and the little island robert louis steven\n",
      "\n",
      "  Average training loss: 1.25\n",
      "  Training epoch took: 0:01:36\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 2.43\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:16:31 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "# Running the model\n",
    "total_t0 = time.time()\n",
    "training_stats = []\n",
    "model = model.to(device)\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "        model.zero_grad()\n",
    "        outputs = model(b_input_ids,\n",
    "                          labels=b_labels,\n",
    "                          attention_mask = b_masks,\n",
    "                          token_type_ids=None)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        batch_loss = loss.item()\n",
    "        total_train_loss += batch_loss\n",
    "\n",
    "        # Get sample every x batches.\n",
    "        if step % sample_every == 0 and not step == 0:\n",
    "\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            sample_outputs = model.generate(\n",
    "                                    bos_token_id=random.randint(1,30000),\n",
    "                                    do_sample=True,\n",
    "                                    top_k=50,\n",
    "                                    max_length = 200,\n",
    "                                    top_p=0.95,\n",
    "                                    num_return_sequences=1\n",
    "                                )\n",
    "            for i, sample_output in enumerate(sample_outputs):\n",
    "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
    "\n",
    "            model.train()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs  = model(b_input_ids,\n",
    "                             attention_mask = b_masks,\n",
    "                            labels=b_labels)\n",
    "\n",
    "            loss = outputs[0]\n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        total_eval_loss += batch_loss\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQTvJ1vRP7u4"
   },
   "source": [
    "Let's view the summary of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1709776124992,
     "user": {
      "displayName": "Eshan Prashar",
      "userId": "03910558186089522689"
     },
     "user_tz": 360
    },
    "id": "6O_NbXFGMukX",
    "outputId": "65221c6c-98a1-4aa8-9819-f47f3e4d80e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.149535</td>\n",
       "      <td>5.847560</td>\n",
       "      <td>0:01:35</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.480528</td>\n",
       "      <td>3.759224</td>\n",
       "      <td>0:01:36</td>\n",
       "      <td>0:00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.494364</td>\n",
       "      <td>3.371041</td>\n",
       "      <td>0:01:36</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.931924</td>\n",
       "      <td>2.987054</td>\n",
       "      <td>0:01:36</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.423084</td>\n",
       "      <td>2.720094</td>\n",
       "      <td>0:01:36</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.024492</td>\n",
       "      <td>2.514761</td>\n",
       "      <td>0:01:36</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.728603</td>\n",
       "      <td>2.452179</td>\n",
       "      <td>0:01:36</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.495106</td>\n",
       "      <td>2.440395</td>\n",
       "      <td>0:01:36</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.335499</td>\n",
       "      <td>2.417466</td>\n",
       "      <td>0:01:36</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.245222</td>\n",
       "      <td>2.425793</td>\n",
       "      <td>0:01:36</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss Training Time Validation Time\n",
       "epoch                                                          \n",
       "1           9.149535     5.847560       0:01:35         0:00:03\n",
       "2           4.480528     3.759224       0:01:36         0:00:04\n",
       "3           3.494364     3.371041       0:01:36         0:00:03\n",
       "4           2.931924     2.987054       0:01:36         0:00:03\n",
       "5           2.423084     2.720094       0:01:36         0:00:03\n",
       "6           2.024492     2.514761       0:01:36         0:00:03\n",
       "7           1.728603     2.452179       0:01:36         0:00:03\n",
       "8           1.495106     2.440395       0:01:36         0:00:03\n",
       "9           1.335499     2.417466       0:01:36         0:00:03\n",
       "10          1.245222     2.425793       0:01:36         0:00:03"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the stats\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.#\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfjYoa6WmkN6"
   },
   "source": [
    "# Display Model Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1709776136067,
     "user": {
      "displayName": "Eshan Prashar",
      "userId": "03910558186089522689"
     },
     "user_tz": 360
    },
    "id": "8PIiVlDYCtSq",
    "outputId": "f82f5d63-de3a-457e-f397-139a2f5e9241"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GPT-2 model has 148 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "transformer.wte.weight                                  (50259, 768)\n",
      "transformer.wpe.weight                                   (1024, 768)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "transformer.h.0.ln_1.weight                                   (768,)\n",
      "transformer.h.0.ln_1.bias                                     (768,)\n",
      "transformer.h.0.attn.c_attn.weight                       (768, 2304)\n",
      "transformer.h.0.attn.c_attn.bias                             (2304,)\n",
      "transformer.h.0.attn.c_proj.weight                        (768, 768)\n",
      "transformer.h.0.attn.c_proj.bias                              (768,)\n",
      "transformer.h.0.ln_2.weight                                   (768,)\n",
      "transformer.h.0.ln_2.bias                                     (768,)\n",
      "transformer.h.0.mlp.c_fc.weight                          (768, 3072)\n",
      "transformer.h.0.mlp.c_fc.bias                                (3072,)\n",
      "transformer.h.0.mlp.c_proj.weight                        (3072, 768)\n",
      "transformer.h.0.mlp.c_proj.bias                               (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "transformer.ln_f.weight                                       (768,)\n",
      "transformer.ln_f.bias                                         (768,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:2]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[2:14]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-2:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2079Qyn8Mt8"
   },
   "source": [
    "# Saving & Loading Fine-Tuned Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3287,
     "status": "ok",
     "timestamp": 1709776205707,
     "user": {
      "displayName": "Eshan Prashar",
      "userId": "03910558186089522689"
     },
     "user_tz": 360
    },
    "id": "6ulTWaOr8QNY",
    "outputId": "e6135405-3aae-4519-df83-a47468b7bae2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to /home/studio-lab-user/sagemaker-studiolab-notebooks/models/full_data_2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/studio-lab-user/sagemaker-studiolab-notebooks/models/full_data_2/tokenizer_config.json',\n",
       " '/home/studio-lab-user/sagemaker-studiolab-notebooks/models/full_data_2/special_tokens_map.json',\n",
       " '/home/studio-lab-user/sagemaker-studiolab-notebooks/models/full_data_2/vocab.json',\n",
       " '/home/studio-lab-user/sagemaker-studiolab-notebooks/models/full_data_2/merges.txt',\n",
       " '/home/studio-lab-user/sagemaker-studiolab-notebooks/models/full_data_2/added_tokens.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the model for future use\n",
    "\n",
    "output_dir = os.getcwd()+ '/models/full_data_2'\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLf6rbRglYhQ"
   },
   "source": [
    "# Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 865,
     "status": "ok",
     "timestamp": 1709776475130,
     "user": {
      "displayName": "Eshan Prashar",
      "userId": "03910558186089522689"
     },
     "user_tz": 360
    },
    "id": "v4XhewaV93-_",
    "outputId": "ce5c21f1-03f3-4b48-86aa-a3d3b74514ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[49421,    25,   554,  8876]], device='cuda:0')\n",
      "0: classic: In philosophy fiction literature fiction theology spirituality poetry short stories theology short stories theology historical fiction non fiction theology american  oe de cervantes. introduction. _the poem of the martian fathers_. in the second century of american history\n",
      "\n",
      "\n",
      "1: classic: In philosophy fiction literature politics all the traditions and the gods relate and in this way we become gods. e. t. c._ contents chapter the three cities of siddhartha by the river samladeva chapter the four gree\n",
      "\n",
      "\n",
      "2: classic: In philosophy a person is a rational person. only logical sense which man forms is based on his own experience. this is the natural result of selection theory which holds that species of animals is indestructible and at last from that\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trying with a simple prompt\n",
    "model.eval()\n",
    "\n",
    "prompt = \"classic: In philosophy\"\n",
    "\n",
    "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "generated = generated.to(device)\n",
    "\n",
    "print(generated)\n",
    "\n",
    "sample_outputs = model.generate(\n",
    "                                generated,\n",
    "                                do_sample=True,\n",
    "                                top_k=50,\n",
    "                                max_length=50,\n",
    "                                top_p=0.95,\n",
    "                                num_return_sequences=3\n",
    "                                )\n",
    "\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "",
   "provenance": [
    {
     "file_id": "13dZVYEOMhXhkXWfvSMVM1TTtUDrT6Aeh",
     "timestamp": 1709773383735
    },
    {
     "file_id": "1nWmmTV4McFqFqNBL_qSoiY_374x96rC-",
     "timestamp": 1598001591712
    },
    {
     "file_id": "1CvyDx-2bD8Y1uCluvW1bZQ8HNgIkW4fJ",
     "timestamp": 1591296865963
    },
    {
     "file_id": "1vyPIQj1jK2p4whXPojrVOQc6W6eixbt5",
     "timestamp": 1591287949564
    },
    {
     "file_id": "1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX",
     "timestamp": 1590432739171
    },
    {
     "file_id": "1dcucJvUOx6kdopjhVIwIdpby6VXhnvns",
     "timestamp": 1575478354980
    },
    {
     "file_id": "1ywsvwO6thOVOrfagjjfuxEf6xVRxbUNO",
     "timestamp": 1575307876986
    },
    {
     "file_id": "1f_snPs--PVYgZJwT3GwjxqVALFJ0T2-y",
     "timestamp": 1556493831452
    }
   ],
   "version": ""
  },
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "107f25788c0143dfa91b680bea75d721": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "398a1c2de13545df8c98605c36f5b28f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5142ca0af6b4972800c539d8be0df47",
      "max": 548105171,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3c8cd19a405b47afa0d02593cb87131a",
      "value": 548105171
     }
    },
    "3c8cd19a405b47afa0d02593cb87131a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3df436d7e1ee4ac0a03819b4c53dd6ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f5284795a2e42248ae9193be973d2e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4029076684c6476c9a2d9112a1b91313": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a514ac05d06447c88a7159d68f270c85",
      "placeholder": "​",
      "style": "IPY_MODEL_9f5c845ee82947f787ccaa330296c08f",
      "value": "model.safetensors: 100%"
     }
    },
    "70138abb4ced4997ba8e9124e3c62216": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73c327380fc3437dbb44ae5c2695a291": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f27716302494b7ca9a4b0f6b6521a93",
      "placeholder": "​",
      "style": "IPY_MODEL_a6a6fa4578da42418fcdad39f42bb3fb",
      "value": " 124/124 [00:00&lt;00:00, 8.99kB/s]"
     }
    },
    "9840e38ef1504a9b82f7b9a82953b6b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0a8d69844e942eb90157dfff0d05636",
      "placeholder": "​",
      "style": "IPY_MODEL_3df436d7e1ee4ac0a03819b4c53dd6ae",
      "value": " 548M/548M [00:06&lt;00:00, 168MB/s]"
     }
    },
    "9c8a07dbb94c4c749b65ef50ffb2b9d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f5284795a2e42248ae9193be973d2e3",
      "max": 124,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cbaec64da03b463992c3021a29515ff3",
      "value": 124
     }
    },
    "9f27716302494b7ca9a4b0f6b6521a93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f5c845ee82947f787ccaa330296c08f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a5142ca0af6b4972800c539d8be0df47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a514ac05d06447c88a7159d68f270c85": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a629321fdab24be7a9f763330a05dec9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be464c275eb94ed09b63c34a00e8c362",
      "placeholder": "​",
      "style": "IPY_MODEL_eacd9bc141564040b4e6929521a246bd",
      "value": "generation_config.json: 100%"
     }
    },
    "a6a6fa4578da42418fcdad39f42bb3fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be464c275eb94ed09b63c34a00e8c362": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbaec64da03b463992c3021a29515ff3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e6dcdbf38bfc4b839a85b3a9242fdc30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a629321fdab24be7a9f763330a05dec9",
       "IPY_MODEL_9c8a07dbb94c4c749b65ef50ffb2b9d3",
       "IPY_MODEL_73c327380fc3437dbb44ae5c2695a291"
      ],
      "layout": "IPY_MODEL_70138abb4ced4997ba8e9124e3c62216"
     }
    },
    "eacd9bc141564040b4e6929521a246bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "effd586e628a494f8cd9fa5d06435946": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4029076684c6476c9a2d9112a1b91313",
       "IPY_MODEL_398a1c2de13545df8c98605c36f5b28f",
       "IPY_MODEL_9840e38ef1504a9b82f7b9a82953b6b9"
      ],
      "layout": "IPY_MODEL_107f25788c0143dfa91b680bea75d721"
     }
    },
    "f0a8d69844e942eb90157dfff0d05636": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
