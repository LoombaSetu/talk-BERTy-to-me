{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Change working directory to talk-berty-to-me root\n",
    "import os\n",
    "os.chdir(\"D:/University/Projects/AML/talk-berty-to-me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gutenberg = pd.read_csv('data/books_and_genres.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = data_gutenberg.sample(frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# universal_set = set()\n",
    "# def parse_set(string_set):\n",
    "#     return ast.literal_eval(string_set)\n",
    "\n",
    "# for string in list(zip(dev_data['genres'])):\n",
    "#     parsed_set = parse_set(string[0])\n",
    "#     universal_set = universal_set.union(parsed_set)\n",
    "# universal_set_list = list(universal_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_genres = ['fiction', 'classics', 'historical', '20th-century', 'non-fiction', 'literature', 'history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def OneHotEncodeGenres(genres):\n",
    "#     return [1 if genre in genres else 0 for genre in selected_genres]\n",
    "\n",
    "\n",
    "# dev_data.loc[:,'genre_one_hot'] = dev_data['genres'].apply(lambda x: OneHotEncodeGenres(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_data.drop(columns=['genres'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>3686</td>\n",
       "      <td>die ungleichen schalen</td>\n",
       "      <td>Produced by Markus Brenner, Marina Lukas and t...</td>\n",
       "      <td>{'plays'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>3526</td>\n",
       "      <td>galatea</td>\n",
       "      <td>Produced by Carlo Traverso, Claudio Paganelli ...</td>\n",
       "      <td>{'contemporary', 'literary-fiction', 'romance'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>5723</td>\n",
       "      <td>surprising stories</td>\n",
       "      <td>Produced by Susan Skinner, Marilynda Fraser-Cu...</td>\n",
       "      <td>{'unfinished', 'short-stories'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8603</th>\n",
       "      <td>8603</td>\n",
       "      <td>hypatia</td>\n",
       "      <td>Produced by P. J. Riddick\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nH...</td>\n",
       "      <td>{'literary-fiction', 'christian', 'history', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3501</th>\n",
       "      <td>3501</td>\n",
       "      <td>the babes in the wood</td>\n",
       "      <td>Produced by Jonathan Niehof, Suzanne Shell and...</td>\n",
       "      <td>{'picture-books', 'classics', 'fiction', '20th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                   title  \\\n",
       "3686        3686  die ungleichen schalen   \n",
       "3526        3526                 galatea   \n",
       "5723        5723      surprising stories   \n",
       "8603        8603                 hypatia   \n",
       "3501        3501   the babes in the wood   \n",
       "\n",
       "                                                   text  \\\n",
       "3686  Produced by Markus Brenner, Marina Lukas and t...   \n",
       "3526  Produced by Carlo Traverso, Claudio Paganelli ...   \n",
       "5723  Produced by Susan Skinner, Marilynda Fraser-Cu...   \n",
       "8603  Produced by P. J. Riddick\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nH...   \n",
       "3501  Produced by Jonathan Niehof, Suzanne Shell and...   \n",
       "\n",
       "                                                 genres  \n",
       "3686                                          {'plays'}  \n",
       "3526  {'contemporary', 'literary-fiction', 'romance'...  \n",
       "5723                    {'unfinished', 'short-stories'}  \n",
       "8603  {'literary-fiction', 'christian', 'history', '...  \n",
       "3501  {'picture-books', 'classics', 'fiction', '20th...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building vocabulary\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab_iter = iter(dev_data.loc[:,'text'] + dev_data.loc[:,'title'] + dev_data.loc[:,'genres'])\n",
    "def yield_tokens(train_iter):\n",
    "    for text in train_iter:\n",
    "        if not isinstance(text, str):\n",
    "            if type(text) == list:\n",
    "                for t in text:\n",
    "                    yield tokenizer(t)\n",
    "            continue\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(vocab_iter), specials=[\"<unk>\"], min_freq=1000)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\setul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\setul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake\n",
    "r = Rake()\n",
    "def rake_extract(text):\n",
    "    r.extract_keywords_from_text(str(text))\n",
    "    ranked_phrases_with_scores = r.get_ranked_phrases_with_scores()\n",
    "    sorted_phrases = sorted(ranked_phrases_with_scores, key=lambda x: x[0], reverse=True)\n",
    "    if len(sorted_phrases) == 0:\n",
    "        return \"\"\n",
    "    return sorted_phrases[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible improvement is to remove proper nouns before employing rake. Will take more effort.\n",
    "Reduce dataset to just English books. Improve text cleaning to remove redundant symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data.loc[:,'sentences'] = dev_data.loc[:,'text'].apply(lambda x: nltk.tokenize.sent_tokenize(str(x)))\n",
    "dev_data = dev_data.explode('sentences')\n",
    "dev_data.loc[:,'keywords'] = dev_data.loc[:,'sentences'].apply(lambda x: rake_extract(x))\n",
    "dev_data = dev_data.loc[:,['title', 'sentences', 'keywords', 'genres']]\n",
    "dev_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data['label_sentences'] = dev_data.groupby('title')['sentences'].shift(-1)\n",
    "\n",
    "dev_data = dev_data.dropna(subset=['label_sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data['label_keywords'] = dev_data.groupby('title')['keywords'].shift(-1)\n",
    "\n",
    "dev_data = dev_data.dropna(subset=['label_keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>sentences</th>\n",
       "      <th>keywords</th>\n",
       "      <th>genres</th>\n",
       "      <th>label_sentences</th>\n",
       "      <th>label_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>die ungleichen schalen</td>\n",
       "      <td>Produced by Markus Brenner, Marina Lukas and t...</td>\n",
       "      <td>net die ungleichen schalen fünf einaktige dram...</td>\n",
       "      <td>{'plays'}</td>\n",
       "      <td>Den Bühnen und Vereinen gegenüber\\nManuskript.</td>\n",
       "      <td>den bühnen und vereinen gegenüber manuskript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>die ungleichen schalen</td>\n",
       "      <td>Den Bühnen und Vereinen gegenüber\\nManuskript.</td>\n",
       "      <td>den bühnen und vereinen gegenüber manuskript</td>\n",
       "      <td>{'plays'}</td>\n",
       "      <td>Das Recht der Aufführung ist allein durch\\nS. ...</td>\n",
       "      <td>das recht der aufführung ist allein durch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>die ungleichen schalen</td>\n",
       "      <td>Das Recht der Aufführung ist allein durch\\nS. ...</td>\n",
       "      <td>das recht der aufführung ist allein durch</td>\n",
       "      <td>{'plays'}</td>\n",
       "      <td>90 zu erwerben.</td>\n",
       "      <td>90 zu erwerben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>die ungleichen schalen</td>\n",
       "      <td>90 zu erwerben.</td>\n",
       "      <td>90 zu erwerben</td>\n",
       "      <td>{'plays'}</td>\n",
       "      <td>Copyright 1912 S. Fischer, Verlag, Berlin.</td>\n",
       "      <td>copyright 1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>die ungleichen schalen</td>\n",
       "      <td>Copyright 1912 S. Fischer, Verlag, Berlin.</td>\n",
       "      <td>copyright 1912</td>\n",
       "      <td>{'plays'}</td>\n",
       "      <td>Inhalt\\n\\nRasumowsky                       9\\n...</td>\n",
       "      <td>inhalt rasumowsky 9 gentz und fanny elßler 59 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title                                          sentences  \\\n",
       "0  die ungleichen schalen  Produced by Markus Brenner, Marina Lukas and t...   \n",
       "1  die ungleichen schalen     Den Bühnen und Vereinen gegenüber\\nManuskript.   \n",
       "2  die ungleichen schalen  Das Recht der Aufführung ist allein durch\\nS. ...   \n",
       "3  die ungleichen schalen                                    90 zu erwerben.   \n",
       "4  die ungleichen schalen         Copyright 1912 S. Fischer, Verlag, Berlin.   \n",
       "\n",
       "                                            keywords     genres  \\\n",
       "0  net die ungleichen schalen fünf einaktige dram...  {'plays'}   \n",
       "1       den bühnen und vereinen gegenüber manuskript  {'plays'}   \n",
       "2          das recht der aufführung ist allein durch  {'plays'}   \n",
       "3                                     90 zu erwerben  {'plays'}   \n",
       "4                                     copyright 1912  {'plays'}   \n",
       "\n",
       "                                     label_sentences  \\\n",
       "0     Den Bühnen und Vereinen gegenüber\\nManuskript.   \n",
       "1  Das Recht der Aufführung ist allein durch\\nS. ...   \n",
       "2                                    90 zu erwerben.   \n",
       "3         Copyright 1912 S. Fischer, Verlag, Berlin.   \n",
       "4  Inhalt\\n\\nRasumowsky                       9\\n...   \n",
       "\n",
       "                                      label_keywords  \n",
       "0       den bühnen und vereinen gegenüber manuskript  \n",
       "1          das recht der aufführung ist allein durch  \n",
       "2                                     90 zu erwerben  \n",
       "3                                     copyright 1912  \n",
       "4  inhalt rasumowsky 9 gentz und fanny elßler 59 ...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def collate_sentences(batch):\n",
    "    titles, genres, sentences, label_sentences = zip(*batch)\n",
    "    input_sentence = [tokenizer(t) + ['<BOS>'] + tokenizer(s) + ['<EOS>'] +\n",
    "                       tokenizer(g) for t, s, g in zip(titles, sentences, genres)]\n",
    "    label_sentence = [tokenizer(s) for s in label_sentences]\n",
    "    input_tensor = pad_sequence([torch.tensor(vocab.lookup_indices(t)) for t in input_sentence],\n",
    "                                 padding_value=vocab['<pad>'], batch_first=True)\n",
    "    label_tensor = pad_sequence([torch.tensor(vocab.lookup_indices(t)) for t in label_sentence],\n",
    "                                    padding_value=vocab['<pad>'], batch_first=True)\n",
    "    return input_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_keywords(batch):\n",
    "    titles, genres, keywords, label_keywords = zip(*batch)\n",
    "    input_keywords = [tokenizer(t) + ['<BOS>'] + tokenizer(k) + ['<EOS>'] +\n",
    "                       tokenizer(g) for t, k, g in zip(titles, keywords, genres)]\n",
    "    label_keywords = [tokenizer(k) for k in label_keywords]\n",
    "    input_tensor = pad_sequence([torch.tensor(vocab.lookup_indices(k)) for k in input_keywords],\n",
    "                                 padding_value=vocab['<pad>'], batch_first=True)\n",
    "    label_tensor = pad_sequence([torch.tensor(vocab.lookup_indices(k)) for k in label_keywords],\n",
    "                                    padding_value=vocab['<pad>'], batch_first=True)\n",
    "    return input_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From HW4\n",
    "from torch.utils.data import Sampler\n",
    "class BatchSequentialSampler(Sampler):\n",
    "    r\"\"\"Samples batches, s.t. the ith elements of each batch are sequential.\n",
    "\n",
    "    Args:\n",
    "        data_source (Dataset): dataset to sample from\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_source, batch_size):\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __iter__(self):\n",
    "        num_batches = len(self.data_source)//self.batch_size\n",
    "        for i in range(num_batches):\n",
    "            for j in range(self.batch_size):\n",
    "                yield(j * num_batches + i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.data_source)//self.batch_size) * self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_sampler = BatchSequentialSampler(dev_data.loc[\n",
    "    :,['title', 'genres', 'sentences', 'label_sentences']], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dataloader = torch.utils.data.DataLoader(dev_data.loc[\n",
    "    :,['title', 'genres', 'sentences', 'label_sentences']].values, batch_size=8,\n",
    "      shuffle=False, collate_fn=collate_sentences, sampler=sent_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64])\n",
      "torch.Size([8, 39])\n"
     ]
    }
   ],
   "source": [
    "for idx, (input_tensor, label_tensor) in enumerate(sent_dataloader):\n",
    "    print(input_tensor.shape)\n",
    "    print(label_tensor.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_dataloader = torch.utils.data.DataLoader(dev_data.loc[\n",
    "    :,['title', 'genres', 'keywords', 'label_keywords']].values, batch_size=8,\n",
    "      shuffle=False, collate_fn=collate_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 31])\n",
      "torch.Size([8, 21])\n"
     ]
    }
   ],
   "source": [
    "for idx, (input_tensor, label_tensor) in enumerate(keyword_dataloader):\n",
    "    print(input_tensor.shape)\n",
    "    print(label_tensor.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_CACHE_DIR = '/Users/setul/mlpp23/.vector_cache'\n",
    "glove = torchtext.vocab.GloVe('6B', cache=VECTOR_CACHE_DIR)\n",
    "glove_vectors = glove.get_vecs_by_tokens(vocab.get_itos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__ (self, input_dim, embedding_dim, hidden_dim, output_dim,\n",
    "                  num_layers, vocab_size, type_rnn = 'LSTM', bidirectional = True,\n",
    "                  dropout = 0.3, pad_idx = 0, activation = 'tanh'):\n",
    "        super(BiRNN, self).__init__()\n",
    "        self.rnns = []\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        #self.embedding = nn.Embedding.from_pretrained(glove_vectors, padding_idx = pad_idx, freeze=False)\n",
    "        hidden_size = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "        for layer_num in range(num_layers):\n",
    "            input_size = embedding_dim if layer_num == 0 else hidden_size\n",
    "            hidden_size = output_dim if layer_num == num_layers - 1 else hidden_size\n",
    "            if type_rnn == 'LSTM':\n",
    "                rnn = nn.LSTM(input_size, hidden_size, 1, dropout = dropout, bidirectional = bidirectional)\n",
    "            elif type_rnn == 'GRU':\n",
    "                rnn = nn.GRU(input_size, hidden_size, 1, dropout = dropout, bidirectional = bidirectional)\n",
    "            self.rnns.append(rnn)\n",
    "        self.rnns = nn.ModuleList(self.rnns)\n",
    "        self.linear = nn.Linear(hidden_size, output_dim) if bidirectional else nn.Linear(hidden_dim, output_dim)\n",
    "        self.activation = activation\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.num_layers = num_layers\n",
    "        # self.bidirectional = bidirectional\n",
    "        # self.type_rnn = type_rnn\n",
    "        # self.hidden_dim = hidden_dim\n",
    "        # self.embedding_dim = embedding_dim\n",
    "        # self.vocab_size = vocab_size\n",
    "        # self.pad_idx = pad_idx\n",
    "        # self.input_dim = input_dim\n",
    "        # self.output_dim = output_dim\n",
    "    \n",
    "    def forward(self, input, hidden = None):\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.dropout(embedded)\n",
    "        rnn_input = embedded\n",
    "        for layer_num, rnn in enumerate(self.rnns):\n",
    "            output, hidden_output = rnn(rnn_input, hidden)\n",
    "            hidden = hidden_output\n",
    "        output = self.linear(output)\n",
    "        output = torch.tanh(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_CUDA = torch.cuda.is_available()\n",
    "if IS_CUDA:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN_encoder(nn.Module):\n",
    "    def __init__ (self, embedding_dim, hidden_dim,\n",
    "                  vocab_size, num_layers=2, type_rnn = 'LSTM', bidirectional = True,\n",
    "                  dropout = 0.3, pad_idx = 0):\n",
    "        super(BiRNN_encoder, self).__init__()\n",
    "        self.rnns = []\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        hidden_size = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "        input_size = embedding_dim\n",
    "        for layer_num in range(num_layers):\n",
    "            if type_rnn == 'LSTM':\n",
    "                rnn = nn.LSTM(input_size, hidden_size, 1, dropout = dropout,\n",
    "                               bidirectional = bidirectional, batch_first=True)\n",
    "            elif type_rnn == 'GRU':\n",
    "                rnn = nn.GRU(input_size, hidden_size, 1, dropout = dropout,\n",
    "                              bidirectional = bidirectional, batch_first=True)\n",
    "            self.rnns.append(rnn)\n",
    "            input_size = hidden_size*2 if bidirectional else hidden_size\n",
    "        self.rnns = nn.ModuleList(self.rnns)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.type_rnn = type_rnn\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "    def forward(self, input, hidden = None):\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.dropout(embedded)\n",
    "        rnn_input = embedded\n",
    "        for idx, rnn in enumerate(self.rnns):\n",
    "            print(\"rnn_layer\", idx)\n",
    "            output, hidden_output = rnn(rnn_input, hidden)\n",
    "            hidden = hidden_output\n",
    "            rnn_input = output\n",
    "        if self.type_rnn == 'LSTM':\n",
    "            hidden = hidden[0]\n",
    "        if self.bidirectional:\n",
    "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "class BiRNN_decoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size,\n",
    "                  output_dim, dropout = 0.3):\n",
    "        super(BiRNN_decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, 1,\n",
    "                            dropout = dropout, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def forward(self, encoder_output, encoder_hidden, target):\n",
    "        batch_size = encoder_output.size(0)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_input = torch.tensor([vocab['<BOS>']] * batch_size,\n",
    "                                      device=device).view(batch_size, 1)\n",
    "        decoder_outputs = []\n",
    "        if target is None:\n",
    "            count = MAX_LENGTH\n",
    "        else:\n",
    "            count = target.size(1)\n",
    "        for i in range(count):\n",
    "            embedded = self.embedding(decoder_input)\n",
    "            embedded = self.dropout(embedded)\n",
    "            decoder_output, decoder_hidden = self.rnn(embedded, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            _, prediction = decoder_output.topk(1)\n",
    "            if target is not None:\n",
    "                decoder_input = target[:, i].view(batch_size, 1)\n",
    "            else:\n",
    "                decoder_input = prediction.squeeze().detach().view(-1, 1)\n",
    "        decoder_outputs = F.log_softmax(torch.cat(decoder_outputs, dim=1), dim=2)\n",
    "        return decoder_outputs, decoder_hidden, None\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First create seq2seq model unconstrained by keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = BiRNN_encoder(300, 600, len(vocab), 2, 'LSTM', True, 0.3, 0).to(device)\n",
    "decoder = BiRNN_decoder(300, 300, len(vocab), 10, 0.3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAD_CLIP = 1.\n",
    "NUM_EPOCHS = 3\n",
    "\n",
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "    if h is None:\n",
    "        return None\n",
    "    elif isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_layer 0\n",
      "rnn_layer 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "For batched 3-D input, hx and cx should also be 3-D but got (1-D, 1-D) tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[145], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, MAX_LENGTH):  \u001b[38;5;66;03m# Skip <BOS> token\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m     output, hidden, _ \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_fn(output\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m), trg[:, t])\n\u001b[0;32m     46\u001b[0m     teacher_force \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m TEACHER_FORCING_RATIO\n",
      "File \u001b[1;32mc:\\Users\\setul\\miniconda3\\envs\\talk-berty\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\setul\\miniconda3\\envs\\talk-berty\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[141], line 26\u001b[0m, in \u001b[0;36mBiRNN_decoder.forward\u001b[1;34m(self, encoder_output, encoder_hidden, target)\u001b[0m\n\u001b[0;32m     24\u001b[0m embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(decoder_input)\n\u001b[0;32m     25\u001b[0m embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(embedded)\n\u001b[1;32m---> 26\u001b[0m decoder_output, decoder_hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_hidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m decoder_outputs\u001b[38;5;241m.\u001b[39mappend(decoder_output)\n\u001b[0;32m     28\u001b[0m _, prediction \u001b[38;5;241m=\u001b[39m decoder_output\u001b[38;5;241m.\u001b[39mtopk(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\setul\\miniconda3\\envs\\talk-berty\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\setul\\miniconda3\\envs\\talk-berty\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\setul\\miniconda3\\envs\\talk-berty\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:865\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m    863\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor batched 3-D input, hx and cx should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    864\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malso be 3-D but got (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D) tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 865\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: For batched 3-D input, hx and cx should also be 3-D but got (1-D, 1-D) tensors"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "GRAD_CLIP = 1.\n",
    "NUM_EPOCHS = 3\n",
    "TEACHER_FORCING_RATIO = 0.5\n",
    "MAX_LENGTH = 12\n",
    "\n",
    "# Assuming the existence of 'encoder' and 'decoder' instances,\n",
    "# and 'sent_dataloader' as your DataLoader instance for training data.\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "val_losses = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, batch in enumerate(sent_dataloader):\n",
    "        src, trg = batch\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        \n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        output, hidden = encoder(src)\n",
    "        hidden = repackage_hidden(hidden)  # Detach hidden state\n",
    "\n",
    "        # Initial input to decoder is the <BOS> token\n",
    "        input = trg[:, 0]  # Assuming trg[:, 0] is the <BOS> token for each sequence in the batch\n",
    "\n",
    "        loss = 0\n",
    "        for t in range(1, MAX_LENGTH):  # Skip <BOS> token\n",
    "            output, hidden, _ = decoder(input, hidden, trg)\n",
    "            loss += loss_fn(output.squeeze(1), trg[:, t])\n",
    "            teacher_force = random.random() < TEACHER_FORCING_RATIO\n",
    "            top1 = output.argmax(2)[:, 0]\n",
    "            input = trg[:, t] if teacher_force else top1\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), GRAD_CLIP)\n",
    "        torch.nn.utils.clip_grad_norm_(decoder.parameters(), GRAD_CLIP)\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(sent_dataloader)\n",
    "    print(f'Epoch {epoch+1}, Loss: {average_loss:.4f}')\n",
    "    val_losses.append(average_loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "talk-berty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
